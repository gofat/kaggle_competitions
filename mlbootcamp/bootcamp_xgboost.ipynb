{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача \"Выход из он-лайн игры\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой задаче необходимо научиться предсказывать, остается ли участник в он-лайн игре или уходит из нее. Уходом считается отсутствие его в игре в течение недели.\n",
    "\n",
    " \n",
    "\n",
    "Всего используется 12 признаков, вычисленных за 2 предыдущие недели:\n",
    "\n",
    "- maxPlayerLevel - максимальный уровень игры, который прошел игрок\n",
    "- numberOfAttemptedLevels - количество уровней, которые попытался пройти игрок\n",
    "- attemptsOnTheHighestLevel - число попыток, сделанных на самом высоком уровне\n",
    "- totalNumOfAttempts - общее число попыток\n",
    "- averageNumOfTurnsPerCompletedLevel - среднее количество ходов, выполненных на успешно пройденных уровнях\n",
    "- doReturnOnLowerLevels - делал ли игрок возвраты к игре на уже пройденных уровнях\n",
    "- numberOfBoostersUsed - количество использованных бустеров\n",
    "- fractionOfUsefullBoosters - количество бустеров, использованных во время успешных попыток (игрок прошел уровнь)\n",
    "- totalScore - общее количество набранных очков\n",
    "- totalBonusScore - общее количество набранных бонусных очков\n",
    "- totalStarsCount - общее количество набранных звезд\n",
    "- numberOfDaysActuallyPlayed - количество дней, когда пользователь играл в игру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве ответа для данной задачи принимается текстовый файл, каждая строка которого соответствует строке в файле x_test.csv и содержит значение от 0 до 1 (вероятность того, что пользователь останется в игре). В качестве критерия качества решения задачи используется <b>логарифмическая функция потерь (<i>logloss</i>)</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read dataframes\n",
    "x_train = pd.read_csv('x_train.csv',sep=';')\n",
    "x_test = pd.read_csv('x_test.csv',sep=';')\n",
    "y_train = pd.read_csv('y_train.csv',names=['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# added dision\n",
    "for n,i in enumerate(x_train.columns[:11]):\n",
    "    for j in x_train.columns[n+1:11]:\n",
    "        x_train[j+'_div_'+i] = x_train[j]/(x_train[i]+0.01)\n",
    "        \n",
    "for n,i in enumerate(x_test.columns[:11]):\n",
    "    for j in x_test.columns[n+1:11]:\n",
    "        x_test[j+'_div_'+i] = x_test[j]/(x_test[i]+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# added log\n",
    "for i in x_train.columns:\n",
    "    x_train['log_'+str(i)] = np.log(x_train[i]+0.01)\n",
    "    \n",
    "for i in x_test.columns:\n",
    "    x_test['log_'+str(i)] = np.log(x_test[i]+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scaling for metric methods\n",
    "sc = StandardScaler()\n",
    "x_t = sc.fit_transform(x_train)\n",
    "x_tst = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth=2\n",
      "rf scored -0.385322756261\n",
      "for depth=4\n",
      "rf scored -0.384991445317\n",
      "for depth=6\n",
      "rf scored -0.384884239521\n",
      "for depth=8\n",
      "rf scored -0.384957487902\n",
      "for depth=10\n",
      "rf scored -0.384715513499\n",
      "for depth=12\n",
      "rf scored -0.38483575851\n",
      "for depth=14\n",
      "rf scored -0.384675802652\n",
      "for depth=16\n",
      "rf scored -0.384523615865\n",
      "for depth=18\n",
      "rf scored -0.384561127513\n",
      "for depth=20\n",
      "rf scored -0.384524350505\n",
      "for depth=22\n",
      "rf scored -0.384667080127\n",
      "for depth=24\n",
      "rf scored -0.38447856747\n",
      "for depth=26\n",
      "rf scored -0.384489879898\n",
      "for depth=28\n",
      "rf scored -0.384515640067\n",
      "for depth=30\n",
      "rf scored -0.384480492183\n",
      "for depth=32\n",
      "rf scored -0.384482856626\n",
      "for depth=34\n",
      "rf scored -0.384376625794\n",
      "for depth=36\n",
      "rf scored -0.384435215951\n",
      "for depth=38\n",
      "rf scored -0.384576073078\n"
     ]
    }
   ],
   "source": [
    "# try rf\n",
    "for i in range(2,40,2):\n",
    "    print \"for depth={}\".format(i)\n",
    "    clf = RandomForestClassifier(n_estimators=320,max_depth=8,n_jobs=-1,min_samples_leaf=i)\n",
    "    #gb = GradientBoostingClassifier(n_estimators=120,max_depth=i)\n",
    "    print \"rf scored {}\".format(cross_val_score(clf,x_t,y_train.result,\n",
    "                                             n_jobs=-1,scoring='neg_log_loss').mean())\n",
    "    #print \"gb scored {}\".format(cross_val_score(gb,x_t,y_train.result,\n",
    "    #                                         n_jobs=-1,scoring='neg_log_loss').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# polynomial features pow. 2\n",
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "def run_xgb(train, test, target, eta=0.01, random_state=0):\n",
    "    #eta = 0.1\n",
    "    max_depth = 5\n",
    "    subsample = 1\n",
    "    colsample_bytree = 0.7\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 2,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 1000\n",
    "    early_stopping_rounds = 50\n",
    "    test_size = 0.25\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=test_size, \n",
    "                                                          random_state=random_state, stratify=target)\n",
    "    # TODO change split \n",
    "    print('Length train:', X_train.shape[0])\n",
    "    print('Length valid:', X_valid.shape[0])\n",
    "    #y_train = X_train[target]\n",
    "    #y_valid = X_valid[target]\n",
    "    # TODO delete upper code\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "    # sparse matrix ???\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions, score = run_xgb(poly.fit_transform(x_train), poly.transform(x_test), y_train.result, eta=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions)[1].to_csv('result_xgboost_' + str(datetime.datetime.now()) + '.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
