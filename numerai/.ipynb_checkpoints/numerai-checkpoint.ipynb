{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('numerai_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.263669</td>\n",
       "      <td>0.711012</td>\n",
       "      <td>0.730641</td>\n",
       "      <td>0.259069</td>\n",
       "      <td>0.331150</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.468118</td>\n",
       "      <td>0.426362</td>\n",
       "      <td>0.545662</td>\n",
       "      <td>0.472496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869772</td>\n",
       "      <td>0.219606</td>\n",
       "      <td>0.690553</td>\n",
       "      <td>0.697929</td>\n",
       "      <td>0.332535</td>\n",
       "      <td>0.500681</td>\n",
       "      <td>0.418926</td>\n",
       "      <td>0.272475</td>\n",
       "      <td>0.822392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828056</td>\n",
       "      <td>0.433518</td>\n",
       "      <td>0.435617</td>\n",
       "      <td>0.209394</td>\n",
       "      <td>0.508133</td>\n",
       "      <td>0.296114</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.876144</td>\n",
       "      <td>0.201528</td>\n",
       "      <td>0.630515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.235018</td>\n",
       "      <td>0.588986</td>\n",
       "      <td>0.767599</td>\n",
       "      <td>0.585097</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.960031</td>\n",
       "      <td>0.732236</td>\n",
       "      <td>0.543159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.590072</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.921637</td>\n",
       "      <td>0.542368</td>\n",
       "      <td>0.729199</td>\n",
       "      <td>0.979151</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>0.854326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847301</td>\n",
       "      <td>0.894065</td>\n",
       "      <td>0.791371</td>\n",
       "      <td>0.721615</td>\n",
       "      <td>0.202686</td>\n",
       "      <td>0.845608</td>\n",
       "      <td>0.046535</td>\n",
       "      <td>0.200791</td>\n",
       "      <td>0.654688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796596</td>\n",
       "      <td>0.276844</td>\n",
       "      <td>0.234234</td>\n",
       "      <td>0.798410</td>\n",
       "      <td>0.129723</td>\n",
       "      <td>0.794306</td>\n",
       "      <td>0.174816</td>\n",
       "      <td>0.823313</td>\n",
       "      <td>0.209920</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094406</td>\n",
       "      <td>0.817543</td>\n",
       "      <td>0.342794</td>\n",
       "      <td>0.215916</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.207310</td>\n",
       "      <td>0.845106</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.016130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.036370</td>\n",
       "      <td>0.438090</td>\n",
       "      <td>0.219633</td>\n",
       "      <td>0.100569</td>\n",
       "      <td>0.097791</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.337548</td>\n",
       "      <td>0.382942</td>\n",
       "      <td>0.160545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074038</td>\n",
       "      <td>0.044325</td>\n",
       "      <td>0.844283</td>\n",
       "      <td>0.792098</td>\n",
       "      <td>0.842606</td>\n",
       "      <td>0.133044</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.795792</td>\n",
       "      <td>0.128112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  0.263669  0.711012  0.730641  0.259069  0.331150  0.300947  0.468118   \n",
       "1  0.828056  0.433518  0.435617  0.209394  0.508133  0.296114  0.082211   \n",
       "2  0.089681  0.590072  0.715500  0.921637  0.542368  0.729199  0.979151   \n",
       "3  0.796596  0.276844  0.234234  0.798410  0.129723  0.794306  0.174816   \n",
       "4  0.040664  0.036370  0.438090  0.219633  0.100569  0.097791  0.089305   \n",
       "\n",
       "   feature8  feature9  feature10   ...    feature13  feature14  feature15  \\\n",
       "0  0.426362  0.545662   0.472496   ...     0.869772   0.219606   0.690553   \n",
       "1  0.876144  0.201528   0.630515   ...     0.570470   0.235018   0.588986   \n",
       "2  0.009172  0.929291   0.854326   ...     0.847301   0.894065   0.791371   \n",
       "3  0.823313  0.209920   0.008414   ...     0.094406   0.817543   0.342794   \n",
       "4  0.337548  0.382942   0.160545   ...     0.074038   0.044325   0.844283   \n",
       "\n",
       "   feature16  feature17  feature18  feature19  feature20  feature21  target  \n",
       "0   0.697929   0.332535   0.500681   0.418926   0.272475   0.822392       1  \n",
       "1   0.767599   0.585097   0.458801   0.960031   0.732236   0.543159       0  \n",
       "2   0.721615   0.202686   0.845608   0.046535   0.200791   0.654688       0  \n",
       "3   0.215916   0.015114   0.207310   0.845106   0.017104   0.016130       0  \n",
       "4   0.792098   0.842606   0.133044   0.002375   0.795792   0.128112       1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.495515</td>\n",
       "      <td>0.504806</td>\n",
       "      <td>0.501291</td>\n",
       "      <td>0.525232</td>\n",
       "      <td>0.490325</td>\n",
       "      <td>0.501399</td>\n",
       "      <td>0.492902</td>\n",
       "      <td>0.500034</td>\n",
       "      <td>0.496661</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508338</td>\n",
       "      <td>0.492883</td>\n",
       "      <td>0.516477</td>\n",
       "      <td>0.534609</td>\n",
       "      <td>0.487273</td>\n",
       "      <td>0.513251</td>\n",
       "      <td>0.496786</td>\n",
       "      <td>0.496528</td>\n",
       "      <td>0.506407</td>\n",
       "      <td>0.507313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286843</td>\n",
       "      <td>0.289952</td>\n",
       "      <td>0.293140</td>\n",
       "      <td>0.289845</td>\n",
       "      <td>0.292437</td>\n",
       "      <td>0.286529</td>\n",
       "      <td>0.284225</td>\n",
       "      <td>0.285824</td>\n",
       "      <td>0.292720</td>\n",
       "      <td>0.281561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291265</td>\n",
       "      <td>0.290822</td>\n",
       "      <td>0.283163</td>\n",
       "      <td>0.292226</td>\n",
       "      <td>0.288464</td>\n",
       "      <td>0.289846</td>\n",
       "      <td>0.292101</td>\n",
       "      <td>0.286538</td>\n",
       "      <td>0.292980</td>\n",
       "      <td>0.499951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.263065</td>\n",
       "      <td>0.247832</td>\n",
       "      <td>0.276403</td>\n",
       "      <td>0.226864</td>\n",
       "      <td>0.250692</td>\n",
       "      <td>0.252745</td>\n",
       "      <td>0.261614</td>\n",
       "      <td>0.240044</td>\n",
       "      <td>0.254334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264428</td>\n",
       "      <td>0.243085</td>\n",
       "      <td>0.278300</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.242321</td>\n",
       "      <td>0.263774</td>\n",
       "      <td>0.242654</td>\n",
       "      <td>0.249704</td>\n",
       "      <td>0.235558</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.479254</td>\n",
       "      <td>0.496178</td>\n",
       "      <td>0.510131</td>\n",
       "      <td>0.539201</td>\n",
       "      <td>0.493210</td>\n",
       "      <td>0.505608</td>\n",
       "      <td>0.487354</td>\n",
       "      <td>0.490177</td>\n",
       "      <td>0.497191</td>\n",
       "      <td>0.476783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.494066</td>\n",
       "      <td>0.524214</td>\n",
       "      <td>0.560189</td>\n",
       "      <td>0.489725</td>\n",
       "      <td>0.512149</td>\n",
       "      <td>0.495928</td>\n",
       "      <td>0.505668</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.747885</td>\n",
       "      <td>0.768643</td>\n",
       "      <td>0.758342</td>\n",
       "      <td>0.777407</td>\n",
       "      <td>0.743655</td>\n",
       "      <td>0.742080</td>\n",
       "      <td>0.739014</td>\n",
       "      <td>0.748659</td>\n",
       "      <td>0.751543</td>\n",
       "      <td>0.730126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777105</td>\n",
       "      <td>0.753093</td>\n",
       "      <td>0.759584</td>\n",
       "      <td>0.793325</td>\n",
       "      <td>0.741703</td>\n",
       "      <td>0.755116</td>\n",
       "      <td>0.744884</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>0.762487</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature1      feature2      feature3      feature4      feature5  \\\n",
       "count  57771.000000  57771.000000  57771.000000  57771.000000  57771.000000   \n",
       "mean       0.495515      0.504806      0.501291      0.525232      0.490325   \n",
       "std        0.286843      0.289952      0.293140      0.289845      0.292437   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000810   \n",
       "25%        0.255061      0.263065      0.247832      0.276403      0.226864   \n",
       "50%        0.479254      0.496178      0.510131      0.539201      0.493210   \n",
       "75%        0.747885      0.768643      0.758342      0.777407      0.743655   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           feature6      feature7      feature8      feature9     feature10  \\\n",
       "count  57771.000000  57771.000000  57771.000000  57771.000000  57771.000000   \n",
       "mean       0.501399      0.492902      0.500034      0.496661      0.491700   \n",
       "std        0.286529      0.284225      0.285824      0.292720      0.281561   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000034   \n",
       "25%        0.250692      0.252745      0.261614      0.240044      0.254334   \n",
       "50%        0.505608      0.487354      0.490177      0.497191      0.476783   \n",
       "75%        0.742080      0.739014      0.748659      0.751543      0.730126   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...          feature13     feature14     feature15     feature16  \\\n",
       "count      ...       57771.000000  57771.000000  57771.000000  57771.000000   \n",
       "mean       ...           0.508338      0.492883      0.516477      0.534609   \n",
       "std        ...           0.291265      0.290822      0.283163      0.292226   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000114   \n",
       "25%        ...           0.264428      0.243085      0.278300      0.289773   \n",
       "50%        ...           0.504100      0.494066      0.524214      0.560189   \n",
       "75%        ...           0.777105      0.753093      0.759584      0.793325   \n",
       "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          feature17     feature18     feature19     feature20     feature21  \\\n",
       "count  57771.000000  57771.000000  57771.000000  57771.000000  57771.000000   \n",
       "mean       0.487273      0.513251      0.496786      0.496528      0.506407   \n",
       "std        0.288464      0.289846      0.292101      0.286538      0.292980   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.242321      0.263774      0.242654      0.249704      0.235558   \n",
       "50%        0.489725      0.512149      0.495928      0.505668      0.512987   \n",
       "75%        0.741703      0.755116      0.744884      0.747680      0.762487   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             target  \n",
       "count  57771.000000  \n",
       "mean       0.507313  \n",
       "std        0.499951  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble #импортируем ensemble\n",
    "from sklearn import cross_validation #импортируем кросс-валидацию\n",
    "kf = cross_validation.KFold(len(train),n_folds=5,shuffle=True)#задаем кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_target = train['target']\n",
    "train = train.drop([\"target\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.263669</td>\n",
       "      <td>0.711012</td>\n",
       "      <td>0.730641</td>\n",
       "      <td>0.259069</td>\n",
       "      <td>0.331150</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.468118</td>\n",
       "      <td>0.426362</td>\n",
       "      <td>0.545662</td>\n",
       "      <td>0.472496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575795</td>\n",
       "      <td>0.869772</td>\n",
       "      <td>0.219606</td>\n",
       "      <td>0.690553</td>\n",
       "      <td>0.697929</td>\n",
       "      <td>0.332535</td>\n",
       "      <td>0.500681</td>\n",
       "      <td>0.418926</td>\n",
       "      <td>0.272475</td>\n",
       "      <td>0.822392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828056</td>\n",
       "      <td>0.433518</td>\n",
       "      <td>0.435617</td>\n",
       "      <td>0.209394</td>\n",
       "      <td>0.508133</td>\n",
       "      <td>0.296114</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.876144</td>\n",
       "      <td>0.201528</td>\n",
       "      <td>0.630515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.235018</td>\n",
       "      <td>0.588986</td>\n",
       "      <td>0.767599</td>\n",
       "      <td>0.585097</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.960031</td>\n",
       "      <td>0.732236</td>\n",
       "      <td>0.543159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.590072</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.921637</td>\n",
       "      <td>0.542368</td>\n",
       "      <td>0.729199</td>\n",
       "      <td>0.979151</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>0.854326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853776</td>\n",
       "      <td>0.847301</td>\n",
       "      <td>0.894065</td>\n",
       "      <td>0.791371</td>\n",
       "      <td>0.721615</td>\n",
       "      <td>0.202686</td>\n",
       "      <td>0.845608</td>\n",
       "      <td>0.046535</td>\n",
       "      <td>0.200791</td>\n",
       "      <td>0.654688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796596</td>\n",
       "      <td>0.276844</td>\n",
       "      <td>0.234234</td>\n",
       "      <td>0.798410</td>\n",
       "      <td>0.129723</td>\n",
       "      <td>0.794306</td>\n",
       "      <td>0.174816</td>\n",
       "      <td>0.823313</td>\n",
       "      <td>0.209920</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231999</td>\n",
       "      <td>0.094406</td>\n",
       "      <td>0.817543</td>\n",
       "      <td>0.342794</td>\n",
       "      <td>0.215916</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.207310</td>\n",
       "      <td>0.845106</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.016130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.036370</td>\n",
       "      <td>0.438090</td>\n",
       "      <td>0.219633</td>\n",
       "      <td>0.100569</td>\n",
       "      <td>0.097791</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.337548</td>\n",
       "      <td>0.382942</td>\n",
       "      <td>0.160545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.074038</td>\n",
       "      <td>0.044325</td>\n",
       "      <td>0.844283</td>\n",
       "      <td>0.792098</td>\n",
       "      <td>0.842606</td>\n",
       "      <td>0.133044</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.795792</td>\n",
       "      <td>0.128112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  0.263669  0.711012  0.730641  0.259069  0.331150  0.300947  0.468118   \n",
       "1  0.828056  0.433518  0.435617  0.209394  0.508133  0.296114  0.082211   \n",
       "2  0.089681  0.590072  0.715500  0.921637  0.542368  0.729199  0.979151   \n",
       "3  0.796596  0.276844  0.234234  0.798410  0.129723  0.794306  0.174816   \n",
       "4  0.040664  0.036370  0.438090  0.219633  0.100569  0.097791  0.089305   \n",
       "\n",
       "   feature8  feature9  feature10    ...      feature12  feature13  feature14  \\\n",
       "0  0.426362  0.545662   0.472496    ...       0.575795   0.869772   0.219606   \n",
       "1  0.876144  0.201528   0.630515    ...       0.000194   0.570470   0.235018   \n",
       "2  0.009172  0.929291   0.854326    ...       0.853776   0.847301   0.894065   \n",
       "3  0.823313  0.209920   0.008414    ...       0.231999   0.094406   0.817543   \n",
       "4  0.337548  0.382942   0.160545    ...       0.009624   0.074038   0.044325   \n",
       "\n",
       "   feature15  feature16  feature17  feature18  feature19  feature20  feature21  \n",
       "0   0.690553   0.697929   0.332535   0.500681   0.418926   0.272475   0.822392  \n",
       "1   0.588986   0.767599   0.585097   0.458801   0.960031   0.732236   0.543159  \n",
       "2   0.791371   0.721615   0.202686   0.845608   0.046535   0.200791   0.654688  \n",
       "3   0.342794   0.215916   0.015114   0.207310   0.845106   0.017104   0.016130  \n",
       "4   0.844283   0.792098   0.842606   0.133044   0.002375   0.795792   0.128112  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['mean'] = train.mean(axis=1)\n",
    "train['std'] = train.std(axis=1)\n",
    "train['median'] = train.median(axis=1)\n",
    "train['var'] = train.var(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_c = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1_feature1\n",
      "feature1_feature2\n",
      "feature1_feature3\n",
      "feature1_feature4\n",
      "feature1_feature5\n",
      "feature1_feature6\n",
      "feature1_feature7\n",
      "feature1_feature8\n",
      "feature1_feature9\n",
      "feature1_feature10\n",
      "feature1_feature11\n",
      "feature1_feature12\n",
      "feature1_feature13\n",
      "feature1_feature14\n",
      "feature1_feature15\n",
      "feature1_feature16\n",
      "feature1_feature17\n",
      "feature1_feature18\n",
      "feature1_feature19\n",
      "feature1_feature20\n",
      "feature1_feature21\n",
      "feature1_mean\n",
      "feature1_std\n",
      "feature1_median\n",
      "feature1_var\n",
      "feature2_feature1\n",
      "feature2_feature2\n",
      "feature2_feature3\n",
      "feature2_feature4\n",
      "feature2_feature5\n",
      "feature2_feature6\n",
      "feature2_feature7\n",
      "feature2_feature8\n",
      "feature2_feature9\n",
      "feature2_feature10\n",
      "feature2_feature11\n",
      "feature2_feature12\n",
      "feature2_feature13\n",
      "feature2_feature14\n",
      "feature2_feature15\n",
      "feature2_feature16\n",
      "feature2_feature17\n",
      "feature2_feature18\n",
      "feature2_feature19\n",
      "feature2_feature20\n",
      "feature2_feature21\n",
      "feature2_mean\n",
      "feature2_std\n",
      "feature2_median\n",
      "feature2_var\n",
      "feature3_feature1\n",
      "feature3_feature2\n",
      "feature3_feature3\n",
      "feature3_feature4\n",
      "feature3_feature5\n",
      "feature3_feature6\n",
      "feature3_feature7\n",
      "feature3_feature8\n",
      "feature3_feature9\n",
      "feature3_feature10\n",
      "feature3_feature11\n",
      "feature3_feature12\n",
      "feature3_feature13\n",
      "feature3_feature14\n",
      "feature3_feature15\n",
      "feature3_feature16\n",
      "feature3_feature17\n",
      "feature3_feature18\n",
      "feature3_feature19\n",
      "feature3_feature20\n",
      "feature3_feature21\n",
      "feature3_mean\n",
      "feature3_std\n",
      "feature3_median\n",
      "feature3_var\n",
      "feature4_feature1\n",
      "feature4_feature2\n",
      "feature4_feature3\n",
      "feature4_feature4\n",
      "feature4_feature5\n",
      "feature4_feature6\n",
      "feature4_feature7\n",
      "feature4_feature8\n",
      "feature4_feature9\n",
      "feature4_feature10\n",
      "feature4_feature11\n",
      "feature4_feature12\n",
      "feature4_feature13\n",
      "feature4_feature14\n",
      "feature4_feature15\n",
      "feature4_feature16\n",
      "feature4_feature17\n",
      "feature4_feature18\n",
      "feature4_feature19\n",
      "feature4_feature20\n",
      "feature4_feature21\n",
      "feature4_mean\n",
      "feature4_std\n",
      "feature4_median\n",
      "feature4_var\n",
      "feature5_feature1\n",
      "feature5_feature2\n",
      "feature5_feature3\n",
      "feature5_feature4\n",
      "feature5_feature5\n",
      "feature5_feature6\n",
      "feature5_feature7\n",
      "feature5_feature8\n",
      "feature5_feature9\n",
      "feature5_feature10\n",
      "feature5_feature11\n",
      "feature5_feature12\n",
      "feature5_feature13\n",
      "feature5_feature14\n",
      "feature5_feature15\n",
      "feature5_feature16\n",
      "feature5_feature17\n",
      "feature5_feature18\n",
      "feature5_feature19\n",
      "feature5_feature20\n",
      "feature5_feature21\n",
      "feature5_mean\n",
      "feature5_std\n",
      "feature5_median\n",
      "feature5_var\n",
      "feature6_feature1\n",
      "feature6_feature2\n",
      "feature6_feature3\n",
      "feature6_feature4\n",
      "feature6_feature5\n",
      "feature6_feature6\n",
      "feature6_feature7\n",
      "feature6_feature8\n",
      "feature6_feature9\n",
      "feature6_feature10\n",
      "feature6_feature11\n",
      "feature6_feature12\n",
      "feature6_feature13\n",
      "feature6_feature14\n",
      "feature6_feature15\n",
      "feature6_feature16\n",
      "feature6_feature17\n",
      "feature6_feature18\n",
      "feature6_feature19\n",
      "feature6_feature20\n",
      "feature6_feature21\n",
      "feature6_mean\n",
      "feature6_std\n",
      "feature6_median\n",
      "feature6_var\n",
      "feature7_feature1\n",
      "feature7_feature2\n",
      "feature7_feature3\n",
      "feature7_feature4\n",
      "feature7_feature5\n",
      "feature7_feature6\n",
      "feature7_feature7\n",
      "feature7_feature8\n",
      "feature7_feature9\n",
      "feature7_feature10\n",
      "feature7_feature11\n",
      "feature7_feature12\n",
      "feature7_feature13\n",
      "feature7_feature14\n",
      "feature7_feature15\n",
      "feature7_feature16\n",
      "feature7_feature17\n",
      "feature7_feature18\n",
      "feature7_feature19\n",
      "feature7_feature20\n",
      "feature7_feature21\n",
      "feature7_mean\n",
      "feature7_std\n",
      "feature7_median\n",
      "feature7_var\n",
      "feature8_feature1\n",
      "feature8_feature2\n",
      "feature8_feature3\n",
      "feature8_feature4\n",
      "feature8_feature5\n",
      "feature8_feature6\n",
      "feature8_feature7\n",
      "feature8_feature8\n",
      "feature8_feature9\n",
      "feature8_feature10\n",
      "feature8_feature11\n",
      "feature8_feature12\n",
      "feature8_feature13\n",
      "feature8_feature14\n",
      "feature8_feature15\n",
      "feature8_feature16\n",
      "feature8_feature17\n",
      "feature8_feature18\n",
      "feature8_feature19\n",
      "feature8_feature20\n",
      "feature8_feature21\n",
      "feature8_mean\n",
      "feature8_std\n",
      "feature8_median\n",
      "feature8_var\n",
      "feature9_feature1\n",
      "feature9_feature2\n",
      "feature9_feature3\n",
      "feature9_feature4\n",
      "feature9_feature5\n",
      "feature9_feature6\n",
      "feature9_feature7\n",
      "feature9_feature8\n",
      "feature9_feature9\n",
      "feature9_feature10\n",
      "feature9_feature11\n",
      "feature9_feature12\n",
      "feature9_feature13\n",
      "feature9_feature14\n",
      "feature9_feature15\n",
      "feature9_feature16\n",
      "feature9_feature17\n",
      "feature9_feature18\n",
      "feature9_feature19\n",
      "feature9_feature20\n",
      "feature9_feature21\n",
      "feature9_mean\n",
      "feature9_std\n",
      "feature9_median\n",
      "feature9_var\n",
      "feature10_feature1\n",
      "feature10_feature2\n",
      "feature10_feature3\n",
      "feature10_feature4\n",
      "feature10_feature5\n",
      "feature10_feature6\n",
      "feature10_feature7\n",
      "feature10_feature8\n",
      "feature10_feature9\n",
      "feature10_feature10\n",
      "feature10_feature11\n",
      "feature10_feature12\n",
      "feature10_feature13\n",
      "feature10_feature14\n",
      "feature10_feature15\n",
      "feature10_feature16\n",
      "feature10_feature17\n",
      "feature10_feature18\n",
      "feature10_feature19\n",
      "feature10_feature20\n",
      "feature10_feature21\n",
      "feature10_mean\n",
      "feature10_std\n",
      "feature10_median\n",
      "feature10_var\n",
      "feature11_feature1\n",
      "feature11_feature2\n",
      "feature11_feature3\n",
      "feature11_feature4\n",
      "feature11_feature5\n",
      "feature11_feature6\n",
      "feature11_feature7\n",
      "feature11_feature8\n",
      "feature11_feature9\n",
      "feature11_feature10\n",
      "feature11_feature11\n",
      "feature11_feature12\n",
      "feature11_feature13\n",
      "feature11_feature14\n",
      "feature11_feature15\n",
      "feature11_feature16\n",
      "feature11_feature17\n",
      "feature11_feature18\n",
      "feature11_feature19\n",
      "feature11_feature20\n",
      "feature11_feature21\n",
      "feature11_mean\n",
      "feature11_std\n",
      "feature11_median\n",
      "feature11_var\n",
      "feature12_feature1\n",
      "feature12_feature2\n",
      "feature12_feature3\n",
      "feature12_feature4\n",
      "feature12_feature5\n",
      "feature12_feature6\n",
      "feature12_feature7\n",
      "feature12_feature8\n",
      "feature12_feature9\n",
      "feature12_feature10\n",
      "feature12_feature11\n",
      "feature12_feature12\n",
      "feature12_feature13\n",
      "feature12_feature14\n",
      "feature12_feature15\n",
      "feature12_feature16\n",
      "feature12_feature17\n",
      "feature12_feature18\n",
      "feature12_feature19\n",
      "feature12_feature20\n",
      "feature12_feature21\n",
      "feature12_mean\n",
      "feature12_std\n",
      "feature12_median\n",
      "feature12_var\n",
      "feature13_feature1\n",
      "feature13_feature2\n",
      "feature13_feature3\n",
      "feature13_feature4\n",
      "feature13_feature5\n",
      "feature13_feature6\n",
      "feature13_feature7\n",
      "feature13_feature8\n",
      "feature13_feature9\n",
      "feature13_feature10\n",
      "feature13_feature11\n",
      "feature13_feature12\n",
      "feature13_feature13\n",
      "feature13_feature14\n",
      "feature13_feature15\n",
      "feature13_feature16\n",
      "feature13_feature17\n",
      "feature13_feature18\n",
      "feature13_feature19\n",
      "feature13_feature20\n",
      "feature13_feature21\n",
      "feature13_mean\n",
      "feature13_std\n",
      "feature13_median\n",
      "feature13_var\n",
      "feature14_feature1\n",
      "feature14_feature2\n",
      "feature14_feature3\n",
      "feature14_feature4\n",
      "feature14_feature5\n",
      "feature14_feature6\n",
      "feature14_feature7\n",
      "feature14_feature8\n",
      "feature14_feature9\n",
      "feature14_feature10\n",
      "feature14_feature11\n",
      "feature14_feature12\n",
      "feature14_feature13\n",
      "feature14_feature14\n",
      "feature14_feature15\n",
      "feature14_feature16\n",
      "feature14_feature17\n",
      "feature14_feature18\n",
      "feature14_feature19\n",
      "feature14_feature20\n",
      "feature14_feature21\n",
      "feature14_mean\n",
      "feature14_std\n",
      "feature14_median\n",
      "feature14_var\n",
      "feature15_feature1\n",
      "feature15_feature2\n",
      "feature15_feature3\n",
      "feature15_feature4\n",
      "feature15_feature5\n",
      "feature15_feature6\n",
      "feature15_feature7\n",
      "feature15_feature8\n",
      "feature15_feature9\n",
      "feature15_feature10\n",
      "feature15_feature11\n",
      "feature15_feature12\n",
      "feature15_feature13\n",
      "feature15_feature14\n",
      "feature15_feature15\n",
      "feature15_feature16\n",
      "feature15_feature17\n",
      "feature15_feature18\n",
      "feature15_feature19\n",
      "feature15_feature20\n",
      "feature15_feature21\n",
      "feature15_mean\n",
      "feature15_std\n",
      "feature15_median\n",
      "feature15_var\n",
      "feature16_feature1\n",
      "feature16_feature2\n",
      "feature16_feature3\n",
      "feature16_feature4\n",
      "feature16_feature5\n",
      "feature16_feature6\n",
      "feature16_feature7\n",
      "feature16_feature8\n",
      "feature16_feature9\n",
      "feature16_feature10\n",
      "feature16_feature11\n",
      "feature16_feature12\n",
      "feature16_feature13\n",
      "feature16_feature14\n",
      "feature16_feature15\n",
      "feature16_feature16\n",
      "feature16_feature17\n",
      "feature16_feature18\n",
      "feature16_feature19\n",
      "feature16_feature20\n",
      "feature16_feature21\n",
      "feature16_mean\n",
      "feature16_std\n",
      "feature16_median\n",
      "feature16_var\n",
      "feature17_feature1\n",
      "feature17_feature2\n",
      "feature17_feature3\n",
      "feature17_feature4\n",
      "feature17_feature5\n",
      "feature17_feature6\n",
      "feature17_feature7\n",
      "feature17_feature8\n",
      "feature17_feature9\n",
      "feature17_feature10\n",
      "feature17_feature11\n",
      "feature17_feature12\n",
      "feature17_feature13\n",
      "feature17_feature14\n",
      "feature17_feature15\n",
      "feature17_feature16\n",
      "feature17_feature17\n",
      "feature17_feature18\n",
      "feature17_feature19\n",
      "feature17_feature20\n",
      "feature17_feature21\n",
      "feature17_mean\n",
      "feature17_std\n",
      "feature17_median\n",
      "feature17_var\n",
      "feature18_feature1\n",
      "feature18_feature2\n",
      "feature18_feature3\n",
      "feature18_feature4\n",
      "feature18_feature5\n",
      "feature18_feature6\n",
      "feature18_feature7\n",
      "feature18_feature8\n",
      "feature18_feature9\n",
      "feature18_feature10\n",
      "feature18_feature11\n",
      "feature18_feature12\n",
      "feature18_feature13\n",
      "feature18_feature14\n",
      "feature18_feature15\n",
      "feature18_feature16\n",
      "feature18_feature17\n",
      "feature18_feature18\n",
      "feature18_feature19\n",
      "feature18_feature20\n",
      "feature18_feature21\n",
      "feature18_mean\n",
      "feature18_std\n",
      "feature18_median\n",
      "feature18_var\n",
      "feature19_feature1\n",
      "feature19_feature2\n",
      "feature19_feature3\n",
      "feature19_feature4\n",
      "feature19_feature5\n",
      "feature19_feature6\n",
      "feature19_feature7\n",
      "feature19_feature8\n",
      "feature19_feature9\n",
      "feature19_feature10\n",
      "feature19_feature11\n",
      "feature19_feature12\n",
      "feature19_feature13\n",
      "feature19_feature14\n",
      "feature19_feature15\n",
      "feature19_feature16\n",
      "feature19_feature17\n",
      "feature19_feature18\n",
      "feature19_feature19\n",
      "feature19_feature20\n",
      "feature19_feature21\n",
      "feature19_mean\n",
      "feature19_std\n",
      "feature19_median\n",
      "feature19_var\n",
      "feature20_feature1\n",
      "feature20_feature2\n",
      "feature20_feature3\n",
      "feature20_feature4\n",
      "feature20_feature5\n",
      "feature20_feature6\n",
      "feature20_feature7\n",
      "feature20_feature8\n",
      "feature20_feature9\n",
      "feature20_feature10\n",
      "feature20_feature11\n",
      "feature20_feature12\n",
      "feature20_feature13\n",
      "feature20_feature14\n",
      "feature20_feature15\n",
      "feature20_feature16\n",
      "feature20_feature17\n",
      "feature20_feature18\n",
      "feature20_feature19\n",
      "feature20_feature20\n",
      "feature20_feature21\n",
      "feature20_mean\n",
      "feature20_std\n",
      "feature20_median\n",
      "feature20_var\n",
      "feature21_feature1\n",
      "feature21_feature2\n",
      "feature21_feature3\n",
      "feature21_feature4\n",
      "feature21_feature5\n",
      "feature21_feature6\n",
      "feature21_feature7\n",
      "feature21_feature8\n",
      "feature21_feature9\n",
      "feature21_feature10\n",
      "feature21_feature11\n",
      "feature21_feature12\n",
      "feature21_feature13\n",
      "feature21_feature14\n",
      "feature21_feature15\n",
      "feature21_feature16\n",
      "feature21_feature17\n",
      "feature21_feature18\n",
      "feature21_feature19\n",
      "feature21_feature20\n",
      "feature21_feature21\n",
      "feature21_mean\n",
      "feature21_std\n",
      "feature21_median\n",
      "feature21_var\n",
      "mean_feature1\n",
      "mean_feature2\n",
      "mean_feature3\n",
      "mean_feature4\n",
      "mean_feature5\n",
      "mean_feature6\n",
      "mean_feature7\n",
      "mean_feature8\n",
      "mean_feature9\n",
      "mean_feature10\n",
      "mean_feature11\n",
      "mean_feature12\n",
      "mean_feature13\n",
      "mean_feature14\n",
      "mean_feature15\n",
      "mean_feature16\n",
      "mean_feature17\n",
      "mean_feature18\n",
      "mean_feature19\n",
      "mean_feature20\n",
      "mean_feature21\n",
      "mean_mean\n",
      "mean_std\n",
      "mean_median\n",
      "mean_var\n",
      "std_feature1\n",
      "std_feature2\n",
      "std_feature3\n",
      "std_feature4\n",
      "std_feature5\n",
      "std_feature6\n",
      "std_feature7\n",
      "std_feature8\n",
      "std_feature9\n",
      "std_feature10\n",
      "std_feature11\n",
      "std_feature12\n",
      "std_feature13\n",
      "std_feature14\n",
      "std_feature15\n",
      "std_feature16\n",
      "std_feature17\n",
      "std_feature18\n",
      "std_feature19\n",
      "std_feature20\n",
      "std_feature21\n",
      "std_mean\n",
      "std_std\n",
      "std_median\n",
      "std_var\n",
      "median_feature1\n",
      "median_feature2\n",
      "median_feature3\n",
      "median_feature4\n",
      "median_feature5\n",
      "median_feature6\n",
      "median_feature7\n",
      "median_feature8\n",
      "median_feature9\n",
      "median_feature10\n",
      "median_feature11\n",
      "median_feature12\n",
      "median_feature13\n",
      "median_feature14\n",
      "median_feature15\n",
      "median_feature16\n",
      "median_feature17\n",
      "median_feature18\n",
      "median_feature19\n",
      "median_feature20\n",
      "median_feature21\n",
      "median_mean\n",
      "median_std\n",
      "median_median\n",
      "median_var\n",
      "var_feature1\n",
      "var_feature2\n",
      "var_feature3\n",
      "var_feature4\n",
      "var_feature5\n",
      "var_feature6\n",
      "var_feature7\n",
      "var_feature8\n",
      "var_feature9\n",
      "var_feature10\n",
      "var_feature11\n",
      "var_feature12\n",
      "var_feature13\n",
      "var_feature14\n",
      "var_feature15\n",
      "var_feature16\n",
      "var_feature17\n",
      "var_feature18\n",
      "var_feature19\n",
      "var_feature20\n",
      "var_feature21\n",
      "var_mean\n",
      "var_std\n",
      "var_median\n",
      "var_var\n"
     ]
    }
   ],
   "source": [
    "for n,i in enumerate(train_c.keys()):\n",
    "    for j in train_c.keys():\n",
    "        name = i + \"_\" + j\n",
    "        train[name] = train[i] > train[j]\n",
    "        print name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_feature16</th>\n",
       "      <th>var_feature17</th>\n",
       "      <th>var_feature18</th>\n",
       "      <th>var_feature19</th>\n",
       "      <th>var_feature20</th>\n",
       "      <th>var_feature21</th>\n",
       "      <th>var_mean</th>\n",
       "      <th>var_std</th>\n",
       "      <th>var_median</th>\n",
       "      <th>var_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.263669</td>\n",
       "      <td>0.711012</td>\n",
       "      <td>0.730641</td>\n",
       "      <td>0.259069</td>\n",
       "      <td>0.331150</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.468118</td>\n",
       "      <td>0.426362</td>\n",
       "      <td>0.545662</td>\n",
       "      <td>0.472496</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828056</td>\n",
       "      <td>0.433518</td>\n",
       "      <td>0.435617</td>\n",
       "      <td>0.209394</td>\n",
       "      <td>0.508133</td>\n",
       "      <td>0.296114</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.876144</td>\n",
       "      <td>0.201528</td>\n",
       "      <td>0.630515</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.590072</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.921637</td>\n",
       "      <td>0.542368</td>\n",
       "      <td>0.729199</td>\n",
       "      <td>0.979151</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>0.854326</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796596</td>\n",
       "      <td>0.276844</td>\n",
       "      <td>0.234234</td>\n",
       "      <td>0.798410</td>\n",
       "      <td>0.129723</td>\n",
       "      <td>0.794306</td>\n",
       "      <td>0.174816</td>\n",
       "      <td>0.823313</td>\n",
       "      <td>0.209920</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.036370</td>\n",
       "      <td>0.438090</td>\n",
       "      <td>0.219633</td>\n",
       "      <td>0.100569</td>\n",
       "      <td>0.097791</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.337548</td>\n",
       "      <td>0.382942</td>\n",
       "      <td>0.160545</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  0.263669  0.711012  0.730641  0.259069  0.331150  0.300947  0.468118   \n",
       "1  0.828056  0.433518  0.435617  0.209394  0.508133  0.296114  0.082211   \n",
       "2  0.089681  0.590072  0.715500  0.921637  0.542368  0.729199  0.979151   \n",
       "3  0.796596  0.276844  0.234234  0.798410  0.129723  0.794306  0.174816   \n",
       "4  0.040664  0.036370  0.438090  0.219633  0.100569  0.097791  0.089305   \n",
       "\n",
       "   feature8  feature9  feature10   ...     var_feature16  var_feature17  \\\n",
       "0  0.426362  0.545662   0.472496   ...             False          False   \n",
       "1  0.876144  0.201528   0.630515   ...             False          False   \n",
       "2  0.009172  0.929291   0.854326   ...             False          False   \n",
       "3  0.823313  0.209920   0.008414   ...             False           True   \n",
       "4  0.337548  0.382942   0.160545   ...             False          False   \n",
       "\n",
       "   var_feature18  var_feature19  var_feature20  var_feature21  var_mean  \\\n",
       "0          False          False          False          False     False   \n",
       "1          False          False          False          False     False   \n",
       "2          False           True          False          False     False   \n",
       "3          False          False           True           True     False   \n",
       "4          False           True          False          False     False   \n",
       "\n",
       "   var_std  var_median  var_var  \n",
       "0    False       False    False  \n",
       "1    False       False    False  \n",
       "2    False       False    False  \n",
       "3    False       False    False  \n",
       "4    False       False    False  \n",
       "\n",
       "[5 rows x 650 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "      <td>57771.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.495515</td>\n",
       "      <td>0.504806</td>\n",
       "      <td>0.501291</td>\n",
       "      <td>0.525232</td>\n",
       "      <td>0.490325</td>\n",
       "      <td>0.501399</td>\n",
       "      <td>0.492902</td>\n",
       "      <td>0.500034</td>\n",
       "      <td>0.496661</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534609</td>\n",
       "      <td>0.487273</td>\n",
       "      <td>0.513251</td>\n",
       "      <td>0.496786</td>\n",
       "      <td>0.496528</td>\n",
       "      <td>0.506407</td>\n",
       "      <td>0.502711</td>\n",
       "      <td>0.267039</td>\n",
       "      <td>0.485578</td>\n",
       "      <td>0.071279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286843</td>\n",
       "      <td>0.289952</td>\n",
       "      <td>0.293140</td>\n",
       "      <td>0.289845</td>\n",
       "      <td>0.292437</td>\n",
       "      <td>0.286529</td>\n",
       "      <td>0.284225</td>\n",
       "      <td>0.285824</td>\n",
       "      <td>0.292720</td>\n",
       "      <td>0.281561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292226</td>\n",
       "      <td>0.288464</td>\n",
       "      <td>0.289846</td>\n",
       "      <td>0.292101</td>\n",
       "      <td>0.286538</td>\n",
       "      <td>0.292980</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>0.058322</td>\n",
       "      <td>0.139077</td>\n",
       "      <td>0.027699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086754</td>\n",
       "      <td>0.072904</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.005406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.263065</td>\n",
       "      <td>0.247832</td>\n",
       "      <td>0.276403</td>\n",
       "      <td>0.226864</td>\n",
       "      <td>0.250692</td>\n",
       "      <td>0.252745</td>\n",
       "      <td>0.261614</td>\n",
       "      <td>0.240044</td>\n",
       "      <td>0.254334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.242321</td>\n",
       "      <td>0.263774</td>\n",
       "      <td>0.242654</td>\n",
       "      <td>0.249704</td>\n",
       "      <td>0.235558</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.225975</td>\n",
       "      <td>0.390609</td>\n",
       "      <td>0.050552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.479254</td>\n",
       "      <td>0.496178</td>\n",
       "      <td>0.510131</td>\n",
       "      <td>0.539201</td>\n",
       "      <td>0.493210</td>\n",
       "      <td>0.505608</td>\n",
       "      <td>0.487354</td>\n",
       "      <td>0.490177</td>\n",
       "      <td>0.497191</td>\n",
       "      <td>0.476783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560189</td>\n",
       "      <td>0.489725</td>\n",
       "      <td>0.512149</td>\n",
       "      <td>0.495928</td>\n",
       "      <td>0.505668</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.505219</td>\n",
       "      <td>0.266519</td>\n",
       "      <td>0.489821</td>\n",
       "      <td>0.067780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.747885</td>\n",
       "      <td>0.768643</td>\n",
       "      <td>0.758342</td>\n",
       "      <td>0.777407</td>\n",
       "      <td>0.743655</td>\n",
       "      <td>0.742080</td>\n",
       "      <td>0.739014</td>\n",
       "      <td>0.748659</td>\n",
       "      <td>0.751543</td>\n",
       "      <td>0.730126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793325</td>\n",
       "      <td>0.741703</td>\n",
       "      <td>0.755116</td>\n",
       "      <td>0.744884</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>0.762487</td>\n",
       "      <td>0.570781</td>\n",
       "      <td>0.307512</td>\n",
       "      <td>0.578683</td>\n",
       "      <td>0.088463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905031</td>\n",
       "      <td>0.459247</td>\n",
       "      <td>0.943921</td>\n",
       "      <td>0.198046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature1      feature2      feature3      feature4      feature5  \\\n",
       "count  57771.000000  57771.000000  57771.000000  57771.000000  57771.000000   \n",
       "mean       0.495515      0.504806      0.501291      0.525232      0.490325   \n",
       "std        0.286843      0.289952      0.293140      0.289845      0.292437   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000810   \n",
       "25%        0.255061      0.263065      0.247832      0.276403      0.226864   \n",
       "50%        0.479254      0.496178      0.510131      0.539201      0.493210   \n",
       "75%        0.747885      0.768643      0.758342      0.777407      0.743655   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           feature6      feature7      feature8      feature9     feature10  \\\n",
       "count  57771.000000  57771.000000  57771.000000  57771.000000  57771.000000   \n",
       "mean       0.501399      0.492902      0.500034      0.496661      0.491700   \n",
       "std        0.286529      0.284225      0.285824      0.292720      0.281561   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000034   \n",
       "25%        0.250692      0.252745      0.261614      0.240044      0.254334   \n",
       "50%        0.505608      0.487354      0.490177      0.497191      0.476783   \n",
       "75%        0.742080      0.739014      0.748659      0.751543      0.730126   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...          feature16     feature17     feature18     feature19  \\\n",
       "count      ...       57771.000000  57771.000000  57771.000000  57771.000000   \n",
       "mean       ...           0.534609      0.487273      0.513251      0.496786   \n",
       "std        ...           0.292226      0.288464      0.289846      0.292101   \n",
       "min        ...           0.000114      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.289773      0.242321      0.263774      0.242654   \n",
       "50%        ...           0.560189      0.489725      0.512149      0.495928   \n",
       "75%        ...           0.793325      0.741703      0.755116      0.744884   \n",
       "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          feature20     feature21          mean           std        median  \\\n",
       "count  57771.000000  57771.000000  57771.000000  57771.000000  57771.000000   \n",
       "mean       0.496528      0.506407      0.502711      0.267039      0.485578   \n",
       "std        0.286538      0.292980      0.097702      0.058322      0.139077   \n",
       "min        0.000000      0.000000      0.086754      0.072904      0.033424   \n",
       "25%        0.249704      0.235558      0.438345      0.225975      0.390609   \n",
       "50%        0.505668      0.512987      0.505219      0.266519      0.489821   \n",
       "75%        0.747680      0.762487      0.570781      0.307512      0.578683   \n",
       "max        1.000000      1.000000      0.905031      0.459247      0.943921   \n",
       "\n",
       "                var  \n",
       "count  57771.000000  \n",
       "mean       0.071279  \n",
       "std        0.027699  \n",
       "min        0.005406  \n",
       "25%        0.050552  \n",
       "50%        0.067780  \n",
       "75%        0.088463  \n",
       "max        0.198046  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9]\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3855           0.0005           38.16s\n",
      "         2           1.3848           0.0004           34.62s\n",
      "         3           1.3844           0.0003           31.31s\n",
      "         4           1.3836           0.0002           30.26s\n",
      "         5           1.3838           0.0002           29.00s\n",
      "         6           1.3834           0.0003           28.14s\n",
      "         7           1.3830           0.0002           26.61s\n",
      "         8           1.3821           0.0002           25.63s\n",
      "         9           1.3828           0.0001           24.42s\n",
      "        10           1.3819           0.0001           23.24s\n",
      "        20           1.3804          -0.0000           11.27s\n",
      "        30           1.3798           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3850           0.0005           40.15s\n",
      "         1           1.3851           0.0005           44.71s\n",
      "         1           1.3854           0.0005           35.93s\n",
      "         1           1.3853           0.0005           40.59s\n",
      "         2           1.3847           0.0003           38.67s\n",
      "         2           1.3848           0.0004           41.02s\n",
      "         2           1.3847           0.0003           39.04s\n",
      "         2           1.3848           0.0004           38.44s\n",
      "         3           1.3841           0.0003           38.19s\n",
      "         3           1.3844           0.0002           37.39s\n",
      "         3           1.3841           0.0003           37.62s\n",
      "         3           1.3841           0.0003           37.74s\n",
      "         4           1.3841           0.0002           35.55s\n",
      "         4           1.3836           0.0002           36.77s\n",
      "         4           1.3841           0.0003           35.84s\n",
      "         4           1.3837           0.0003           36.32s\n",
      "         5           1.3827           0.0002           35.09s\n",
      "         5           1.3836           0.0002           34.42s\n",
      "         5           1.3834           0.0002           34.18s\n",
      "         5           1.3829           0.0002           34.90s\n",
      "         6           1.3825           0.0003           33.13s\n",
      "         6           1.3830           0.0003           33.15s\n",
      "         6           1.3829           0.0003           32.96s\n",
      "         6           1.3827          -0.0001           33.36s\n",
      "         7           1.3830           0.0002           31.94s\n",
      "         7           1.3830           0.0002           31.62s\n",
      "         7           1.3831           0.0001           32.22s\n",
      "         7           1.3827           0.0001           31.83s\n",
      "         8           1.3829           0.0001           30.03s\n",
      "         8           1.3828           0.0001           30.43s\n",
      "         8           1.3823           0.0001           30.10s\n",
      "         8           1.3824          -0.0000           30.02s\n",
      "         9           1.3827           0.0001           28.62s\n",
      "         9           1.3819           0.0001           28.94s\n",
      "         9           1.3818           0.0001           28.34s\n",
      "         9           1.3824           0.0002           28.68s\n",
      "        10           1.3823           0.0001           26.82s\n",
      "        10           1.3815           0.0001           27.60s\n",
      "        10           1.3822           0.0002           27.06s\n",
      "        10           1.3817           0.0001           27.39s\n",
      "        20           1.3804          -0.0000           13.11s\n",
      "        20           1.3801           0.0000           13.23s\n",
      "        20           1.3794          -0.0001           13.65s\n",
      "        20           1.3799           0.0001           13.44s\n",
      "        30           1.3795          -0.0000            0.00s\n",
      "        30           1.3780          -0.0001            0.00s\n",
      "        30           1.3787          -0.0001            0.00s\n",
      "        30           1.3784           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3854           0.0005           24.86s\n",
      "         2           1.3850           0.0004           23.95s\n",
      "         3           1.3845           0.0002           23.58s\n",
      "         4           1.3841           0.0002           23.00s\n",
      "         5           1.3833           0.0003           22.32s\n",
      "         6           1.3827           0.0003           21.69s\n",
      "         7           1.3832           0.0001           20.51s\n",
      "         8           1.3823           0.0002           19.83s\n",
      "         9           1.3823           0.0001           19.28s\n",
      "        10           1.3819           0.0001           18.37s\n",
      "        20           1.3803           0.0000            8.98s\n",
      "        30           1.3790          -0.0000            0.00s\n",
      "[-0.69150176986680434]\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3853           0.0004           33.97s\n",
      "         2           1.3849           0.0004           33.49s\n",
      "         3           1.3846           0.0003           32.07s\n",
      "         4           1.3841           0.0003           30.75s\n",
      "         5           1.3840           0.0002           29.53s\n",
      "         6           1.3832           0.0003           28.27s\n",
      "         7           1.3828           0.0003           27.06s\n",
      "         8           1.3830           0.0001           25.85s\n",
      "         9           1.3825           0.0002           24.95s\n",
      "        10           1.3823           0.0001           23.95s\n",
      "        20           1.3811          -0.0000           11.48s\n",
      "        30           1.3797           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3855           0.0004           39.77s\n",
      "         1           1.3850           0.0005           41.21s\n",
      "         1           1.3853           0.0003           40.48s\n",
      "         1           1.3853           0.0006           40.01s\n",
      "         2           1.3847           0.0004           38.37s\n",
      "         2           1.3845           0.0003           39.84s\n",
      "         2           1.3849           0.0004           39.00s\n",
      "         2           1.3847           0.0005           38.53s\n",
      "         3           1.3843           0.0004           36.00s\n",
      "         3           1.3844           0.0002           38.65s\n",
      "         3           1.3843           0.0004           37.51s\n",
      "         3           1.3840           0.0003           37.39s\n",
      "         4           1.3838           0.0003           34.83s\n",
      "         4           1.3837           0.0002           37.30s\n",
      "         4           1.3836           0.0002           35.78s\n",
      "         4           1.3840           0.0002           36.84s\n",
      "         5           1.3830           0.0002           33.75s\n",
      "         5           1.3838           0.0003           35.15s\n",
      "         5           1.3832           0.0003           34.23s\n",
      "         5           1.3835           0.0003           35.56s\n",
      "         6           1.3830           0.0002           32.47s\n",
      "         6           1.3834           0.0000           33.65s\n",
      "         6           1.3830           0.0003           32.82s\n",
      "         6           1.3832           0.0002           33.96s\n",
      "         7           1.3823           0.0002           31.35s\n",
      "         7           1.3833           0.0003           32.08s\n",
      "         7           1.3825           0.0001           31.65s\n",
      "         7           1.3827           0.0001           32.75s\n",
      "         8           1.3825           0.0002           30.10s\n",
      "         8           1.3825           0.0001           30.12s\n",
      "         8           1.3829           0.0001           31.19s\n",
      "         8           1.3822           0.0002           30.79s\n",
      "         9           1.3826           0.0001           29.07s\n",
      "         9           1.3817           0.0001           28.65s\n",
      "         9           1.3818           0.0001           29.60s\n",
      "         9           1.3816           0.0002           29.36s\n",
      "        10           1.3822           0.0000           27.62s\n",
      "        10           1.3822           0.0000           27.28s\n",
      "        10           1.3821           0.0001           28.20s\n",
      "        10           1.3816           0.0001           27.74s\n",
      "        20           1.3800           0.0000           13.49s\n",
      "        20           1.3820          -0.0000           13.50s\n",
      "        20           1.3801           0.0001           13.53s\n",
      "        20           1.3798          -0.0001           13.48s\n",
      "        30           1.3786           0.0000            0.00s\n",
      "        30           1.3791          -0.0001            0.00s\n",
      "        30           1.3777           0.0000            0.00s\n",
      "        30           1.3782           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3855           0.0004           26.93s\n",
      "         2           1.3847           0.0005           26.02s\n",
      "         3           1.3845           0.0003           25.19s\n",
      "         4           1.3841           0.0003           24.07s\n",
      "         5           1.3832           0.0003           23.03s\n",
      "         6           1.3828           0.0002           22.17s\n",
      "         7           1.3826           0.0002           21.27s\n",
      "         8           1.3825           0.0001           20.37s\n",
      "         9           1.3825           0.0001           19.43s\n",
      "        10           1.3824          -0.0000           18.58s\n",
      "        20           1.3795          -0.0000            9.31s\n",
      "        30           1.3791          -0.0001            0.00s\n",
      "[-0.69150176986680434, -0.6915880899163116]\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3855           0.0004           33.85s\n",
      "         2           1.3849           0.0005           32.58s\n",
      "         3           1.3838           0.0002           31.31s\n",
      "         4           1.3841           0.0002           30.26s\n",
      "         5           1.3836           0.0004           29.12s\n",
      "         6           1.3835           0.0001           27.99s\n",
      "         7           1.3828           0.0002           26.90s\n",
      "         8           1.3830           0.0002           25.63s\n",
      "         9           1.3825           0.0001           24.51s\n",
      "        10           1.3825           0.0001           23.29s\n",
      "        20           1.3797          -0.0001           11.27s\n",
      "        30           1.3794           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3853           0.0005           41.75s\n",
      "         1           1.3852           0.0005           40.74s\n",
      "         1           1.3853           0.0005           40.57s\n",
      "         1           1.3855           0.0005           41.20s\n",
      "         2           1.3847           0.0004           39.51s\n",
      "         2           1.3849           0.0004           39.08s\n",
      "         2           1.3847           0.0005           38.96s\n",
      "         2           1.3848           0.0005           39.16s\n",
      "         3           1.3844           0.0003           36.78s\n",
      "         3           1.3846           0.0003           37.65s\n",
      "         3           1.3836           0.0003           37.50s\n",
      "         3           1.3845           0.0004           38.86s\n",
      "         4           1.3835           0.0003           35.92s\n",
      "         4           1.3841           0.0003           36.16s\n",
      "         4           1.3837           0.0003           36.12s\n",
      "         4           1.3839           0.0004           37.04s\n",
      "         5           1.3835           0.0002           34.40s\n",
      "         5           1.3833           0.0001           34.21s\n",
      "         5           1.3838           0.0002           34.20s\n",
      "         5           1.3835           0.0003           35.29s\n",
      "         6           1.3828           0.0002           32.95s\n",
      "         6           1.3828           0.0002           32.89s\n",
      "         6           1.3829           0.0003           33.25s\n",
      "         6           1.3828           0.0002           33.77s\n",
      "         7           1.3829           0.0001           31.62s\n",
      "         7           1.3828           0.0001           31.58s\n",
      "         7           1.3822           0.0001           31.39s\n",
      "         7           1.3829           0.0002           32.49s\n",
      "         8           1.3824           0.0000           29.71s\n",
      "         8           1.3820           0.0002           30.03s\n",
      "         8           1.3826           0.0002           30.61s\n",
      "         8           1.3826           0.0002           31.00s\n",
      "         9           1.3825           0.0001           28.40s\n",
      "         9           1.3821           0.0001           29.14s\n",
      "         9           1.3820           0.0000           29.02s\n",
      "         9           1.3819           0.0001           29.66s\n",
      "        10           1.3816           0.0001           27.15s\n",
      "        10           1.3824          -0.0000           27.15s\n",
      "        10           1.3817           0.0001           27.75s\n",
      "        10           1.3815           0.0001           28.17s\n",
      "        20           1.3800          -0.0001           13.30s\n",
      "        20           1.3796          -0.0000           13.45s\n",
      "        20           1.3808          -0.0000           13.66s\n",
      "        20           1.3803           0.0000           13.86s\n",
      "        30           1.3778          -0.0000            0.00s\n",
      "        30           1.3790          -0.0001            0.00s\n",
      "        30           1.3779          -0.0000            0.00s\n",
      "        30           1.3788          -0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3854           0.0005           27.12s\n",
      "         2           1.3850           0.0004           25.18s\n",
      "         3           1.3840           0.0003           25.58s\n",
      "         4           1.3838           0.0002           24.51s\n",
      "         5           1.3830           0.0002           23.45s\n",
      "         6           1.3828           0.0002           22.45s\n",
      "         7           1.3826           0.0001           21.77s\n",
      "         8           1.3828           0.0002           20.73s\n",
      "         9           1.3823          -0.0000           19.39s\n",
      "        10           1.3821           0.0001           18.16s\n",
      "        20           1.3796           0.0000            9.01s\n",
      "        30           1.3784          -0.0001            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-28:\n",
      "Process PoolWorker-27:\n",
      "Process PoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "    task = get()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 359, in get\n",
      "    return recv()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d31a658960e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0malg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#класификатор на градиентном бустинге\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#обучаем класификатор\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#к списку результатов добавляем средний получившийся на кросс-валидации результат по roc_auc score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m                                               fit_params)\n\u001b[1;32m-> 1433\u001b[1;33m                       for train, test in cv)\n\u001b[0m\u001b[0;32m   1434\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = []#список результатов\n",
    "n_est = [x for x in range(2,10,1)]\n",
    "print n_est#выводим число деревьев\n",
    "for n in n_est:\n",
    "    alg = ensemble.GradientBoostingClassifier(n_estimators=30, verbose=True, subsample=0.5, max_leaf_nodes = 4, min_samples_leaf=n, max_features='auto')#класификатор на градиентном бустинге\n",
    "    alg.fit(train, train_target)#обучаем класификатор\n",
    "    score.append(cross_validation.cross_val_score(alg,train, train_target,cv=kf, n_jobs=-1,scoring='log_loss').mean())\n",
    "    print score\n",
    "    #к списку результатов добавляем средний получившийся на кросс-валидации результат по roc_auc score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "rf_score = []\n",
    "#result = np.zeros(len(train))\n",
    "models = []\n",
    "n_est = xrange(290,310,2)\n",
    "for n in n_est:\n",
    "    rf = RandomForestClassifier(n_estimators=300, verbose=1, n_jobs=-1, min_samples_split=5, max_leaf_nodes=13, min_samples_leaf=2)\n",
    "    models.append(rf.fit(train, train_target))\n",
    "    rf_score.append(cross_validation.cross_val_score(rf,train, train_target,cv=kf, n_jobs=-1,scoring='log_loss').mean())\n",
    "    print rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression #имортируем логисчтиескую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "score = []\n",
    "models = []\n",
    "c_est = np.linspace(0.01,10,num=20)\n",
    "for c in c_est:\n",
    "    logr = LogisticRegression(penalty='l2',C=c,n_jobs=-1,verbose=True)#логистическая регрессия\n",
    "    #models.append(logr.fit(train, train_target))\n",
    "    score.append(cross_validation.cross_val_score(logr,train, train_target,cv=kf, n_jobs=-1,scoring='log_loss').mean())\n",
    "    print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_score = []\n",
    "n = np.linspace(120,200,10)\n",
    "for nn in n:\n",
    "#p_list = np.linspace(1,10)\n",
    "#for p in p_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors=nn,n_jobs=-1)\n",
    "    knn_score.append(cross_validation.cross_val_score(knn,train, train_target,cv=kf, n_jobs=-1,scoring='log_loss').mean())\n",
    "    print knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('numerai_tournament_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.zeros(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_fea = test.drop(['t_id'],axis=1)\n",
    "test_id = test.t_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.853061</td>\n",
       "      <td>0.991828</td>\n",
       "      <td>0.350143</td>\n",
       "      <td>0.654192</td>\n",
       "      <td>0.909093</td>\n",
       "      <td>0.862609</td>\n",
       "      <td>0.463147</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.406167</td>\n",
       "      <td>0.415224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925065</td>\n",
       "      <td>0.913353</td>\n",
       "      <td>0.653512</td>\n",
       "      <td>0.962262</td>\n",
       "      <td>0.951630</td>\n",
       "      <td>0.886714</td>\n",
       "      <td>0.352522</td>\n",
       "      <td>0.108802</td>\n",
       "      <td>0.945558</td>\n",
       "      <td>0.007984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966091</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.560994</td>\n",
       "      <td>0.951211</td>\n",
       "      <td>0.135138</td>\n",
       "      <td>0.932749</td>\n",
       "      <td>0.711090</td>\n",
       "      <td>0.762113</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.983598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784351</td>\n",
       "      <td>0.456816</td>\n",
       "      <td>0.823934</td>\n",
       "      <td>0.225814</td>\n",
       "      <td>0.391988</td>\n",
       "      <td>0.058691</td>\n",
       "      <td>0.431277</td>\n",
       "      <td>0.403834</td>\n",
       "      <td>0.130560</td>\n",
       "      <td>0.922161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.810224</td>\n",
       "      <td>0.389078</td>\n",
       "      <td>0.263295</td>\n",
       "      <td>0.125305</td>\n",
       "      <td>0.482722</td>\n",
       "      <td>0.182144</td>\n",
       "      <td>0.590933</td>\n",
       "      <td>0.853296</td>\n",
       "      <td>0.213104</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711413</td>\n",
       "      <td>0.946470</td>\n",
       "      <td>0.260575</td>\n",
       "      <td>0.757511</td>\n",
       "      <td>0.769617</td>\n",
       "      <td>0.473157</td>\n",
       "      <td>0.411123</td>\n",
       "      <td>0.958093</td>\n",
       "      <td>0.385117</td>\n",
       "      <td>0.240546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242545</td>\n",
       "      <td>0.930955</td>\n",
       "      <td>0.553269</td>\n",
       "      <td>0.543342</td>\n",
       "      <td>0.130096</td>\n",
       "      <td>0.862469</td>\n",
       "      <td>0.982298</td>\n",
       "      <td>0.396792</td>\n",
       "      <td>0.813272</td>\n",
       "      <td>0.550736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906435</td>\n",
       "      <td>0.380640</td>\n",
       "      <td>0.439768</td>\n",
       "      <td>0.689768</td>\n",
       "      <td>0.793589</td>\n",
       "      <td>0.289476</td>\n",
       "      <td>0.980922</td>\n",
       "      <td>0.307403</td>\n",
       "      <td>0.251703</td>\n",
       "      <td>0.938767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.116848</td>\n",
       "      <td>0.097879</td>\n",
       "      <td>0.021589</td>\n",
       "      <td>0.275826</td>\n",
       "      <td>0.911225</td>\n",
       "      <td>0.082386</td>\n",
       "      <td>0.020275</td>\n",
       "      <td>0.133655</td>\n",
       "      <td>0.124748</td>\n",
       "      <td>0.119933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113870</td>\n",
       "      <td>0.964152</td>\n",
       "      <td>0.095757</td>\n",
       "      <td>0.763537</td>\n",
       "      <td>0.842659</td>\n",
       "      <td>0.966074</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>0.021992</td>\n",
       "      <td>0.986931</td>\n",
       "      <td>0.307394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  0.853061  0.991828  0.350143  0.654192  0.909093  0.862609  0.463147   \n",
       "1  0.966091  0.725498  0.560994  0.951211  0.135138  0.932749  0.711090   \n",
       "2  0.810224  0.389078  0.263295  0.125305  0.482722  0.182144  0.590933   \n",
       "3  0.242545  0.930955  0.553269  0.543342  0.130096  0.862469  0.982298   \n",
       "4  0.116848  0.097879  0.021589  0.275826  0.911225  0.082386  0.020275   \n",
       "\n",
       "   feature8  feature9  feature10    ...      feature12  feature13  feature14  \\\n",
       "0  0.911227  0.406167   0.415224    ...       0.925065   0.913353   0.653512   \n",
       "1  0.762113  0.021480   0.983598    ...       0.784351   0.456816   0.823934   \n",
       "2  0.853296  0.213104   0.165800    ...       0.711413   0.946470   0.260575   \n",
       "3  0.396792  0.813272   0.550736    ...       0.906435   0.380640   0.439768   \n",
       "4  0.133655  0.124748   0.119933    ...       0.113870   0.964152   0.095757   \n",
       "\n",
       "   feature15  feature16  feature17  feature18  feature19  feature20  feature21  \n",
       "0   0.962262   0.951630   0.886714   0.352522   0.108802   0.945558   0.007984  \n",
       "1   0.225814   0.391988   0.058691   0.431277   0.403834   0.130560   0.922161  \n",
       "2   0.757511   0.769617   0.473157   0.411123   0.958093   0.385117   0.240546  \n",
       "3   0.689768   0.793589   0.289476   0.980922   0.307403   0.251703   0.938767  \n",
       "4   0.763537   0.842659   0.966074   0.065846   0.021992   0.986931   0.307394  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "for mod in models:\n",
    "    prediction = mod.predict_proba(test_fea)\n",
    "    result += prediction[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result/len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record = np.vstack((test_id,result)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.30900000e+03,   5.29342832e-02],\n",
       "       [  9.01700000e+03,   4.98715673e-02],\n",
       "       [  1.07090000e+04,   5.30230012e-02],\n",
       "       ..., \n",
       "       [  1.35000000e+03,   5.30115281e-02],\n",
       "       [  9.70900000e+03,   5.25117198e-02],\n",
       "       [  7.29300000e+03,   5.27236245e-02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record=pd.DataFrame(record)\n",
    "record[0]=record[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record.to_csv('result.csv', header=['t_id','probability'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
