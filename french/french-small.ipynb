{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "import shutil\n",
    "import zipcode\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Use of this metric is not recommended; for illustration only. \n",
    "    See other regression metrics on sklearn docs:\n",
    "      http://scikit-learn.org/stable/modules/classes.html#regression-metrics\n",
    "    Use like any other metric\n",
    "    >>> y_true = [3, -0.5, 2, 7]; y_pred = [2.5, -0.3, 2, 8]\n",
    "    >>> mean_absolute_percentage_error(y_true, y_pred)\n",
    "    Out[]: 24.791666666666668\n",
    "    \"\"\"\n",
    "\n",
    "    ## Note: does not handle mix 1d representation\n",
    "    #if _is_1d(y_true): \n",
    "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(preds, dtrain): \n",
    "    \n",
    "    labels = dtrain.get_label()\n",
    "    \n",
    "    return 'mape',np.mean(np.abs((labels - preds) / labels)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2705: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Fr_train.csv', sep=';')\n",
    "test = pd.read_csv('Fr_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation = train.select_dtypes(exclude=['object']).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = train.prime_tot_ttc\n",
    "train = train.drop(['prime_tot_ttc'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "post_state = []\n",
    "post_wage = []\n",
    "post_population = []\n",
    "\n",
    "for i in train.codepostal.values:\n",
    "    \n",
    "    try:\n",
    "        state = zipcode.isequal(str(i)).state\n",
    "        post_state.append(state)\n",
    "    except:\n",
    "        post_state.append('nothing')\n",
    "\n",
    "    try:\n",
    "        wage = int(zipcode.isequal(str(i)).wage)\n",
    "        post_wage.append(wage)\n",
    "    except:\n",
    "        post_wage.append(0)\n",
    "        \n",
    "    try:\n",
    "        pop = int(zipcode.isequal(str(i)).population)\n",
    "        post_population.append(pop)\n",
    "    except:\n",
    "        post_population.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "post_state_test = []\n",
    "post_wage_test = []\n",
    "post_population_test = []\n",
    "\n",
    "for i in test.codepostal.values:\n",
    "    \n",
    "    try:\n",
    "        state = zipcode.isequal(str(i)).state\n",
    "        post_state_test.append(state)\n",
    "    except:\n",
    "        post_state_test.append('no_state')\n",
    "        \n",
    "    try:\n",
    "        wage = int(zipcode.isequal(str(i)).wage)\n",
    "        post_wage_test.append(wage)\n",
    "    except:\n",
    "        post_wage_test.append(0)\n",
    "        \n",
    "    try:\n",
    "        pop = int(zipcode.isequal(str(i)).population)\n",
    "        post_population_test.append(pop)\n",
    "    except:\n",
    "        post_population_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['state'] = post_state_test\n",
    "test['wage'] = post_wage_test\n",
    "test['population'] = post_population_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.drop(['codepostal'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['state'] = post_state\n",
    "train['wage'] = post_wage\n",
    "train['population'] = post_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['codepostal'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['id'],axis=1)\n",
    "test_id = test.id\n",
    "test = test.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.fillna(train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.fillna(test.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dummy = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dummy = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       12953.2699           13.61m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       12811.8879           12.86m\n",
      "         2       11743.1195           13.56m\n",
      "         1       12858.4264           13.09m\n",
      "         2       11582.6015           12.79m\n",
      "         3       10661.4085           13.42m\n",
      "         2       11614.0179           13.08m\n",
      "         3       10552.4292           12.67m\n",
      "         4        9792.9024           13.31m\n",
      "         3       10560.1436           12.96m\n",
      "         4        9694.7332           12.68m\n",
      "         5        9028.9715           13.16m\n",
      "         4        9682.4202           12.98m\n",
      "         5        8927.6022           12.54m\n",
      "         6        8388.0141           13.06m\n",
      "         5        8925.0966           12.84m\n",
      "         6        8294.9674           12.50m\n",
      "         7        7832.5701           13.03m\n",
      "         6        8286.7187           12.74m\n",
      "         7        7755.2553           12.33m\n",
      "         8        7356.1133           12.89m\n",
      "         7        7736.0802           12.56m\n",
      "         8        7265.3777           12.27m\n",
      "         9        6947.3345           12.89m\n",
      "         8        7243.5375           12.55m\n",
      "         9        6821.8894           12.29m\n",
      "        10        6586.9694           12.78m\n",
      "         9        6834.7297           12.44m\n",
      "        10        6463.0469           12.19m\n",
      "        10        6449.9577           12.28m\n",
      "        20        4472.0003           11.85m\n",
      "        20        4372.8023           11.50m\n",
      "        20        4321.3590           11.69m\n",
      "        30        3521.7365           10.83m\n",
      "        30        3590.1778           11.20m\n",
      "        30        3461.2929           10.99m\n",
      "        40        3083.4039           10.41m\n",
      "        40        3099.0891           10.76m\n",
      "        40        2987.6396           10.64m\n",
      "        50        2761.3133            9.97m\n",
      "        50        2784.3651           10.34m\n",
      "        50        2710.4390           10.10m\n",
      "        60        2565.5024            9.45m\n",
      "        60        2591.0288            9.90m\n",
      "        60        2522.7521            9.67m\n",
      "        70        2438.7987            9.00m\n",
      "        70        2459.8644            9.44m\n",
      "        70        2375.7104            9.32m\n",
      "        80        2326.2329            8.53m\n",
      "        80        2352.3025            8.96m\n",
      "        80        2282.3884            8.83m\n",
      "        90        2253.5048            8.16m\n",
      "        90        2286.5003            8.50m\n",
      "        90        2212.8636            8.41m\n",
      "       100        2201.3201            7.71m\n",
      "       100        2164.0574            7.96m\n",
      "       100        2234.6040            8.10m\n",
      "       200        1928.7804            4.45m\n",
      "       200        1892.9381            4.65m\n",
      "       200        1961.1835            4.72m\n",
      "       300        1797.7310            2.11m\n",
      "       300        1817.5853            2.20m\n",
      "       300        1755.5732            2.20m\n",
      "       400        1705.6123            0.00s\n",
      "       400        1719.0811            0.00s\n",
      "       400        1673.9858            0.00s\n",
      "[-9.8458576609694362]\n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       12706.1691           21.59m\n",
      "         1       12574.9226           20.31m\n",
      "         1       12620.2881           20.75m\n",
      "         2       11276.8889           21.60m\n",
      "         2       11156.5268           20.11m\n",
      "         2       11182.4160           20.60m\n",
      "         3       10090.3367           21.51m\n",
      "         3        9977.8083           20.12m\n",
      "         3        9990.5904           20.61m\n",
      "         4        9128.8601           21.41m\n",
      "         4        9022.1582           20.09m\n",
      "         4        9023.6353           20.61m\n",
      "         5        8310.7335           21.37m\n",
      "         5        8210.5999           20.10m\n",
      "         5        8207.2479           20.61m\n",
      "         6        7622.9502           21.24m\n",
      "         6        7528.6301           20.01m\n",
      "         6        7516.6958           20.50m\n",
      "         7        7019.0537           21.17m\n",
      "         7        6963.3650           19.97m\n",
      "         7        6916.8968           20.54m\n",
      "         8        6450.2165           19.99m\n",
      "         8        6529.7925           21.18m\n",
      "         8        6423.3136           20.47m\n",
      "         9        6031.8100           19.87m\n",
      "         9        6108.7751           21.12m\n",
      "         9        6010.1889           20.49m\n",
      "        10        5664.4299           19.76m\n",
      "        10        5750.1576           20.99m\n",
      "        10        5637.0341           20.36m\n",
      "        20        3784.0043           18.83m\n",
      "        20        3800.3959           20.12m\n",
      "        20        3701.6146           19.42m\n",
      "        30        3045.2863           17.98m\n",
      "        30        2951.2146           18.38m\n",
      "        30        3067.0579           19.01m\n",
      "        40        2657.2435           17.36m\n",
      "        40        2622.0678           17.97m\n",
      "        40        2579.5023           17.74m\n",
      "        50        2411.1622           16.52m\n",
      "        50        2336.1874           16.74m\n",
      "        50        2382.3341           17.08m\n",
      "        60        2267.1860           15.66m\n",
      "        60        2178.4133           15.75m\n",
      "        60        2237.0349           16.19m\n",
      "        70        2187.4522           14.52m\n",
      "        70        2070.7673           14.88m\n",
      "        70        2145.1114           15.31m\n",
      "        80        2102.3921           13.78m\n",
      "        80        2003.4885           14.03m\n",
      "        80        2071.0288           14.46m\n",
      "        90        2047.7344           12.95m\n",
      "        90        1949.7496           13.30m\n",
      "        90        2009.5961           13.61m\n",
      "       100        1995.0581           12.28m\n",
      "       100        1901.3143           12.63m\n",
      "       100        1954.5091           12.90m\n",
      "       200        1719.7016            7.07m\n",
      "       200        1643.1164            7.29m\n",
      "       200        1669.1655            7.46m\n",
      "       300        1572.4002            3.33m\n",
      "       300        1535.4714            3.40m\n",
      "       300        1537.6948            3.49m\n",
      "       400        1495.7498            0.00s\n",
      "       400        1460.1066            0.00s\n",
      "       400        1464.3842            0.00s\n",
      "[-9.8458576609694362, -9.4841709870608053]\n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       12551.6725           32.60m\n",
      "         1       12427.2896           30.73m\n",
      "         1       12467.2629           31.37m\n",
      "         2       10995.4580           32.60m\n",
      "         2       10890.1932           30.52m\n",
      "         2       10909.6839           31.18m\n",
      "         3        9737.9648           32.40m\n",
      "         3        9642.6139           30.51m\n",
      "         3        9648.5359           31.20m\n",
      "         4        8679.4188           32.31m\n",
      "         4        8598.5752           30.49m\n",
      "         4        8574.2976           31.19m\n",
      "         5        7830.9662           32.18m\n",
      "         5        7746.4853           30.48m\n",
      "         5        7717.5631           31.06m\n",
      "         6        7036.2724           30.35m\n",
      "         6        7098.3870           32.11m\n",
      "         6        7006.2256           31.01m\n",
      "         7        6457.3621           30.26m\n",
      "         7        6495.5061           32.01m\n",
      "         7        6396.2413           30.89m\n",
      "         8        5980.1975           30.30m\n",
      "         8        5987.0054           31.93m\n",
      "         8        5912.3286           30.83m\n",
      "         9        5577.6143           30.31m\n",
      "         9        5578.1123           31.87m\n",
      "         9        5484.8678           30.81m\n",
      "        10        5199.3880           30.27m\n",
      "        10        5235.4541           31.86m\n",
      "        10        5140.3602           30.74m\n",
      "        20        3396.3960           29.52m\n",
      "        20        3295.5688           29.97m\n",
      "        20        3340.1717           31.00m\n",
      "        30        2674.2277           28.52m\n",
      "        30        2613.0561           28.63m\n",
      "        30        2650.4193           29.79m\n",
      "        40        2344.6144           26.67m\n",
      "        40        2301.2172           26.98m\n",
      "        40        2331.6901           28.01m\n",
      "        50        2147.3729           25.30m\n",
      "        50        2106.7626           25.20m\n",
      "        50        2126.6309           26.33m\n",
      "        60        2028.8211           23.64m\n",
      "        60        1942.7493           23.95m\n",
      "        60        2018.0653           24.81m\n",
      "        70        1943.6208           22.27m\n",
      "        70        1856.4805           22.52m\n",
      "        70        1925.2390           23.22m\n",
      "        80        1873.4630           20.71m\n",
      "        80        1800.2674           21.10m\n",
      "        80        1860.7355           21.70m\n",
      "        90        1813.0367           19.57m\n",
      "        90        1753.3809           19.96m\n",
      "        90        1805.5526           20.52m\n",
      "       100        1773.4441           18.40m\n",
      "       100        1717.6805           18.79m\n",
      "       100        1769.3181           19.33m\n",
      "       200        1510.5528           10.65m\n",
      "       200        1483.6497           10.83m\n",
      "       200        1509.9129           11.02m\n",
      "       300        1397.3626            5.01m\n",
      "       300        1376.1292            5.05m\n",
      "       300        1386.7478            5.15m\n",
      "       400        1324.8863            0.00s\n",
      "       400        1316.5375            0.00s\n",
      "       400        1304.9436            0.00s\n",
      "[-9.8458576609694362, -9.4841709870608053, -9.2772224484197512]\n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       12388.1405           49.20m\n",
      "         1       12267.3621           46.42m\n",
      "         1       12309.9920           47.58m\n",
      "         2       10724.5907           49.01m\n",
      "         2       10630.0690           46.29m\n",
      "         2       10628.8169           47.34m\n",
      "         3        9352.6766           48.95m\n",
      "         3        9275.1996           46.03m\n",
      "         3        9272.3527           47.44m\n",
      "         4        8173.8140           45.92m\n",
      "         4        8241.7679           48.93m\n",
      "         4        8158.6996           47.12m\n",
      "         5        7265.4685           45.94m\n",
      "         5        7320.8669           48.76m\n",
      "         5        7234.9474           47.06m\n",
      "         6        6523.6650           45.91m\n",
      "         6        6564.9594           48.73m\n",
      "         6        6491.3782           47.03m\n",
      "         7        5911.5312           45.82m\n",
      "         7        5948.1292           48.56m\n",
      "         7        5868.8086           46.98m\n",
      "         8        5401.9875           45.71m\n",
      "         8        5420.7175           48.44m\n",
      "         8        5353.6527           46.82m\n",
      "         9        4977.5314           45.50m\n",
      "         9        4991.7242           48.32m\n",
      "         9        4914.8084           46.65m\n",
      "        10        4618.3129           45.53m\n",
      "        10        4626.7938           48.24m\n",
      "        10        4556.5017           46.54m\n",
      "        20        2923.2099           44.64m\n",
      "        20        2861.0256           45.64m\n",
      "        20        2908.8522           47.32m\n",
      "        30        2401.2475           42.43m\n",
      "        30        2328.5577           43.60m\n",
      "        30        2359.3809           44.71m\n",
      "        40        2128.2688           40.10m\n",
      "        40        2057.9433           40.78m\n",
      "        40        2117.1383           42.42m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-64:\n",
      "Process PoolWorker-60:\n",
      "Process PoolWorker-61:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-62:\n",
      "Process PoolWorker-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 359, in get\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    racquire()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    return recv()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "  File \"/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "    racquire()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for i in range(3,10,1):\n",
    "    gb = GradientBoostingRegressor(n_estimators=400, verbose=1, max_depth=i)\n",
    "    score.append(cross_val_score(gb, train_dummy, target, cv=3, n_jobs=-1,scoring=scorer).mean())\n",
    "    print(i, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
       "             max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, presort='auto',\n",
       "             random_state=None, subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=10)\n",
    "gb.fit(train.select_dtypes(exclude=['object']), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = gb.predict(test.select_dtypes(exclude=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 238.84167098,  238.84167098,  238.84167098, ...,  238.84167098,\n",
       "        238.84167098,  238.84167098])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame([test.id.values,prediction])\n",
    "result = result.transpose()\n",
    "cols = ['ID','COTIS']\n",
    "result.columns = cols\n",
    "result.ID = result.ID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.to_csv('result.csv',sep=';',index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
