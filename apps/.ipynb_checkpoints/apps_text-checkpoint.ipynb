{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_train = pd.read_csv('gender_age_train.csv')\n",
    "gender_test = pd.read_csv('gender_age_test.csv')\n",
    "phone_brand = pd.read_csv('phone_brand_device_model.csv')\n",
    "app_events = pd.read_csv('app_events.csv', dtype={'app_id': np.str})\n",
    "app_labels = pd.read_csv('app_labels.csv',dtype={'app_id': np.str})\n",
    "labels = pd.read_csv('label_categories.csv')\n",
    "events = pd.read_csv('events_new.csv', index_col=0)\n",
    "app_text = pd.read_csv('app_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#app_cat = pd.merge(app_labels,labels,on='label_id')\n",
    "#app_cat_un = app_cat.groupby('app_id', as_index=False).agg({'category' : lambda x: ' '.join(x)})\n",
    "#app_cat_un.shape\n",
    "#app_ev = pd.merge(app_events, app_cat_un, on='app_id')\n",
    "#app_ev.shape\n",
    "#app_text = app_ev.groupby('event_id', as_index = False).agg({'category' : lambda x: ' '.join(x), 'app_id' : lambda x: ' '.join(x)})\n",
    "#app_text.shape\n",
    "#app_text.to_csv('app_text.csv',index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data - events and app_text\n",
    "data = pd.merge(events, app_text, on='event_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop columns from app_ev (?????)\n",
    "# where is app_ev (?)\n",
    "app_ev = app_events.drop(['is_installed', 'is_active'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# app_cnt - count of events for any app\n",
    "app_cnt = app_ev.groupby('app_id', as_index=False)['event_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data - merge of data and app_events\n",
    "data = pd.merge(data, app_events, on='event_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>long_lat</th>\n",
       "      <th>is_morning</th>\n",
       "      <th>is_night</th>\n",
       "      <th>is_day</th>\n",
       "      <th>is_evening</th>\n",
       "      <th>category</th>\n",
       "      <th>app_id_x</th>\n",
       "      <th>app_id_y</th>\n",
       "      <th>is_installed</th>\n",
       "      <th>is_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>2016-05-01 00:54:12</td>\n",
       "      <td>103.65</td>\n",
       "      <td>30.97</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>103.65_30.97</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Property Industry 1.0 Industry tag Relatives 1...</td>\n",
       "      <td>5927333115845830913 -5720078949152207372 -1633...</td>\n",
       "      <td>5927333115845830913</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>2016-05-01 00:54:12</td>\n",
       "      <td>103.65</td>\n",
       "      <td>30.97</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>103.65_30.97</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Property Industry 1.0 Industry tag Relatives 1...</td>\n",
       "      <td>5927333115845830913 -5720078949152207372 -1633...</td>\n",
       "      <td>-5720078949152207372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id            device_id            timestamp  longitude  latitude  \\\n",
       "0         2 -6401643145415154744  2016-05-01 00:54:12     103.65     30.97   \n",
       "1         2 -6401643145415154744  2016-05-01 00:54:12     103.65     30.97   \n",
       "\n",
       "   hour  weekday      long_lat is_morning is_night is_day is_evening  \\\n",
       "0     0        6  103.65_30.97      False     True  False      False   \n",
       "1     0        6  103.65_30.97      False     True  False      False   \n",
       "\n",
       "                                            category  \\\n",
       "0  Property Industry 1.0 Industry tag Relatives 1...   \n",
       "1  Property Industry 1.0 Industry tag Relatives 1...   \n",
       "\n",
       "                                            app_id_x              app_id_y  \\\n",
       "0  5927333115845830913 -5720078949152207372 -1633...   5927333115845830913   \n",
       "1  5927333115845830913 -5720078949152207372 -1633...  -5720078949152207372   \n",
       "\n",
       "   is_installed  is_active  \n",
       "0             1          1  \n",
       "1             1          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO drop duplicates from data (!!!)\n",
    "# duplicates by event_id, device and timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['device_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kick duplicates from phone_brand\n",
    "phone_brand.drop_duplicates(subset='device_id',keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change bool values to int type\n",
    "#data.is_morning = data.is_morning.astype(int)\n",
    "#data.is_night = data.is_night.astype(int)\n",
    "#data.is_day = data.is_day.astype(int)\n",
    "#data.is_evening = data.is_evening.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train and test data - merge of gender... and data\n",
    "train_data = pd.merge(gender_train, data, on='device_id', how='left')\n",
    "test_data = pd.merge(gender_test, data, on='device_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train and test data - merge of ..._data and phone_brand\n",
    "train_data = pd.merge(train_data, phone_brand, on='device_id')\n",
    "test_data = pd.merge(test_data, phone_brand, on='device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill na values with no_data\n",
    "train_data = train_data.fillna('no_data')\n",
    "test_data = test_data.fillna('no_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# app_events_sum - grouped by event app_events\n",
    "#app_events_sum = app_events.groupby(['event_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count of apps, count of installed, count of active\n",
    "#app_cnt = app_events.groupby(['event_id'], as_index=False)['app_id'].count()\n",
    "#installed_sum = app_events.groupby(['event_id'], as_index=False)['is_installed'].sum()\n",
    "#active_sum = app_events.groupby(['event_id'], as_index=False)['is_active'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summary of previous counts\n",
    "#app_data_med = pd.merge(app_cnt, installed_sum, on=['event_id'])\n",
    "#app_data = pd.merge(app_data_med, active_sum, on=['event_id'])\n",
    "#app_data['active_share'] = app_data.is_active/app_data.app_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop gender and age from train_data\n",
    "#train_data = train_data.drop(['gender','age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group = train_data['group']\n",
    "train_data = train_data[['device_id', 'category', 'app_id_x', 'phone_brand', 'device_model']]\n",
    "test_data = test_data[['device_id', 'category', 'app_id_x', 'phone_brand', 'device_model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.category = train_data.category.astype(str)\n",
    "train_data.app_id_x = train_data.app_id_x.astype(str)\n",
    "train_data.phone_brand = train_data.phone_brand.astype(str)\n",
    "train_data.device_model = train_data.device_model.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.category = test_data.category.astype(str)\n",
    "test_data.app_id_x = test_data.app_id_x.astype(str)\n",
    "test_data.phone_brand = test_data.phone_brand.astype(str)\n",
    "test_data.device_model = test_data.device_model.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['text'] = train_data.category + ' ' + train_data.app_id_x + ' ' + \\\n",
    "train_data.phone_brand + ' ' + train_data.device_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['text'] = test_data.category + ' ' + test_data.app_id_x + ' ' + \\\n",
    "test_data.phone_brand + ' ' + test_data.device_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 6)\n",
      "(112071, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186716, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(min_df=2, max_df=0.75, stop_words='english')\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(total.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 17687)\n",
      "(112071, 17687)\n"
     ]
    }
   ],
   "source": [
    "print(X[:train_data.shape[0]].shape)\n",
    "print(X[train_data.shape[0]:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# count devices in events\\nhour_cnt = train_data.groupby(['device_id'], as_index=False)['hour'].count().rename(columns={'hour':'device_cnt'})\\n# hour activities\\nhour_avg = train_data.groupby(['device_id'], as_index=False)['hour'].mean().rename(columns={'hour':'hour_avg'})\\nhour_med = train_data.groupby(['device_id'], as_index=False)['hour'].median().rename(columns={'hour':'hour_med'})\\nhour_min = train_data.groupby(['device_id'], as_index=False)['hour'].min().rename(columns={'hour':'hour_min'})\\nhour_max = train_data.groupby(['device_id'], as_index=False)['hour'].max().rename(columns={'hour':'hour_max'})\\n# weekday activities\\nweekday_avg = train_data.groupby(['device_id'], as_index=False)['weekday'].mean().rename(columns={'weekday':'weekday_avg'})\\nweekday_med = train_data.groupby(['device_id'], as_index=False)['weekday'].median().rename(columns={'weekday':'weekday_med'})\\nweekday_min = train_data.groupby(['device_id'], as_index=False)['weekday'].min().rename(columns={'weekday':'weekday_min'})\\nweekday_max = train_data.groupby(['device_id'], as_index=False)['weekday'].max().rename(columns={'weekday':'weekday_max'})\\n# part of day activities\\nmorning_sum = train_data.groupby(['device_id'], as_index=False)['is_morning'].sum().rename(columns={'is_morning':'morning_sum'})\\nmorning_avg = train_data.groupby(['device_id'], as_index=False)['is_morning'].mean().rename(columns={'is_morning':'morning_avg'})\\nday_sum = train_data.groupby(['device_id'], as_index=False)['is_day'].sum().rename(columns={'is_morning':'day_sum'})\\nday_avg = train_data.groupby(['device_id'], as_index=False)['is_day'].mean().rename(columns={'is_morning':'day_avg'})\\nnight_sum = train_data.groupby(['device_id'], as_index=False)['is_night'].sum().rename(columns={'is_night':'night_sum'})\\nnight_avg = train_data.groupby(['device_id'], as_index=False)['is_night'].mean().rename(columns={'is_night':'night_avg'})\\nevening_sum = train_data.groupby(['device_id'], as_index=False)['is_evening'].sum().rename(columns={'is_evening':'evening_sum'})\\nevening_avg = train_data.groupby(['device_id'], as_index=False)['is_evening'].mean().rename(columns={'is_evening':'evening_avg'})\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# count devices in events\n",
    "hour_cnt = train_data.groupby(['device_id'], as_index=False)['hour'].count().rename(columns={'hour':'device_cnt'})\n",
    "# hour activities\n",
    "hour_avg = train_data.groupby(['device_id'], as_index=False)['hour'].mean().rename(columns={'hour':'hour_avg'})\n",
    "hour_med = train_data.groupby(['device_id'], as_index=False)['hour'].median().rename(columns={'hour':'hour_med'})\n",
    "hour_min = train_data.groupby(['device_id'], as_index=False)['hour'].min().rename(columns={'hour':'hour_min'})\n",
    "hour_max = train_data.groupby(['device_id'], as_index=False)['hour'].max().rename(columns={'hour':'hour_max'})\n",
    "# weekday activities\n",
    "weekday_avg = train_data.groupby(['device_id'], as_index=False)['weekday'].mean().rename(columns={'weekday':'weekday_avg'})\n",
    "weekday_med = train_data.groupby(['device_id'], as_index=False)['weekday'].median().rename(columns={'weekday':'weekday_med'})\n",
    "weekday_min = train_data.groupby(['device_id'], as_index=False)['weekday'].min().rename(columns={'weekday':'weekday_min'})\n",
    "weekday_max = train_data.groupby(['device_id'], as_index=False)['weekday'].max().rename(columns={'weekday':'weekday_max'})\n",
    "# part of day activities\n",
    "morning_sum = train_data.groupby(['device_id'], as_index=False)['is_morning'].sum().rename(columns={'is_morning':'morning_sum'})\n",
    "morning_avg = train_data.groupby(['device_id'], as_index=False)['is_morning'].mean().rename(columns={'is_morning':'morning_avg'})\n",
    "day_sum = train_data.groupby(['device_id'], as_index=False)['is_day'].sum().rename(columns={'is_morning':'day_sum'})\n",
    "day_avg = train_data.groupby(['device_id'], as_index=False)['is_day'].mean().rename(columns={'is_morning':'day_avg'})\n",
    "night_sum = train_data.groupby(['device_id'], as_index=False)['is_night'].sum().rename(columns={'is_night':'night_sum'})\n",
    "night_avg = train_data.groupby(['device_id'], as_index=False)['is_night'].mean().rename(columns={'is_night':'night_avg'})\n",
    "evening_sum = train_data.groupby(['device_id'], as_index=False)['is_evening'].sum().rename(columns={'is_evening':'evening_sum'})\n",
    "evening_avg = train_data.groupby(['device_id'], as_index=False)['is_evening'].mean().rename(columns={'is_evening':'evening_avg'})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# count devices in events\\nhour_cnt_test = test_data.groupby(['device_id'], as_index=False)['hour'].count().rename(columns={'hour':'device_cnt'})\\n# hour activities\\nhour_avg_test = test_data.groupby(['device_id'], as_index=False)['hour'].mean().rename(columns={'hour':'hour_avg'})\\nhour_med_test = test_data.groupby(['device_id'], as_index=False)['hour'].median().rename(columns={'hour':'hour_med'})\\nhour_min_test = test_data.groupby(['device_id'], as_index=False)['hour'].min().rename(columns={'hour':'hour_min'})\\nhour_max_test = test_data.groupby(['device_id'], as_index=False)['hour'].max().rename(columns={'hour':'hour_max'})\\n# weekday activities\\nweekday_avg_test = test_data.groupby(['device_id'], as_index=False)['weekday'].mean().rename(columns={'weekday':'weekday_avg'})\\nweekday_med_test = test_data.groupby(['device_id'], as_index=False)['weekday'].median().rename(columns={'weekday':'weekday_med'})\\nweekday_min_test = test_data.groupby(['device_id'], as_index=False)['weekday'].min().rename(columns={'weekday':'weekday_min'})\\nweekday_max_test = test_data.groupby(['device_id'], as_index=False)['weekday'].max().rename(columns={'weekday':'weekday_max'})\\n# part of day activities\\nmorning_sum_test = test_data.groupby(['device_id'], as_index=False)['is_morning'].sum().rename(columns={'is_morning':'morning_sum'})\\nmorning_avg_test = test_data.groupby(['device_id'], as_index=False)['is_morning'].mean().rename(columns={'is_morning':'morning_avg'})\\nday_sum_test = test_data.groupby(['device_id'], as_index=False)['is_day'].sum().rename(columns={'is_morning':'day_sum'})\\nday_avg_test = test_data.groupby(['device_id'], as_index=False)['is_day'].mean().rename(columns={'is_morning':'day_avg'})\\nnight_sum_test = test_data.groupby(['device_id'], as_index=False)['is_night'].sum().rename(columns={'is_night':'night_sum'})\\nnight_avg_test = test_data.groupby(['device_id'], as_index=False)['is_night'].mean().rename(columns={'is_night':'night_avg'})\\nevening_sum_test = test_data.groupby(['device_id'], as_index=False)['is_evening'].sum().rename(columns={'is_evening':'evening_sum'})\\nevening_avg_test = test_data.groupby(['device_id'], as_index=False)['is_evening'].mean().rename(columns={'is_evening':'evening_avg'})\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# count devices in events\n",
    "hour_cnt_test = test_data.groupby(['device_id'], as_index=False)['hour'].count().rename(columns={'hour':'device_cnt'})\n",
    "# hour activities\n",
    "hour_avg_test = test_data.groupby(['device_id'], as_index=False)['hour'].mean().rename(columns={'hour':'hour_avg'})\n",
    "hour_med_test = test_data.groupby(['device_id'], as_index=False)['hour'].median().rename(columns={'hour':'hour_med'})\n",
    "hour_min_test = test_data.groupby(['device_id'], as_index=False)['hour'].min().rename(columns={'hour':'hour_min'})\n",
    "hour_max_test = test_data.groupby(['device_id'], as_index=False)['hour'].max().rename(columns={'hour':'hour_max'})\n",
    "# weekday activities\n",
    "weekday_avg_test = test_data.groupby(['device_id'], as_index=False)['weekday'].mean().rename(columns={'weekday':'weekday_avg'})\n",
    "weekday_med_test = test_data.groupby(['device_id'], as_index=False)['weekday'].median().rename(columns={'weekday':'weekday_med'})\n",
    "weekday_min_test = test_data.groupby(['device_id'], as_index=False)['weekday'].min().rename(columns={'weekday':'weekday_min'})\n",
    "weekday_max_test = test_data.groupby(['device_id'], as_index=False)['weekday'].max().rename(columns={'weekday':'weekday_max'})\n",
    "# part of day activities\n",
    "morning_sum_test = test_data.groupby(['device_id'], as_index=False)['is_morning'].sum().rename(columns={'is_morning':'morning_sum'})\n",
    "morning_avg_test = test_data.groupby(['device_id'], as_index=False)['is_morning'].mean().rename(columns={'is_morning':'morning_avg'})\n",
    "day_sum_test = test_data.groupby(['device_id'], as_index=False)['is_day'].sum().rename(columns={'is_morning':'day_sum'})\n",
    "day_avg_test = test_data.groupby(['device_id'], as_index=False)['is_day'].mean().rename(columns={'is_morning':'day_avg'})\n",
    "night_sum_test = test_data.groupby(['device_id'], as_index=False)['is_night'].sum().rename(columns={'is_night':'night_sum'})\n",
    "night_avg_test = test_data.groupby(['device_id'], as_index=False)['is_night'].mean().rename(columns={'is_night':'night_avg'})\n",
    "evening_sum_test = test_data.groupby(['device_id'], as_index=False)['is_evening'].sum().rename(columns={'is_evening':'evening_sum'})\n",
    "evening_avg_test = test_data.groupby(['device_id'], as_index=False)['is_evening'].mean().rename(columns={'is_evening':'evening_avg'})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nresult_train = pd.merge(hour_cnt, hour_avg, on='device_id')\\nresult_train = pd.merge(result_train, hour_med, on='device_id')\\nresult_train = pd.merge(result_train, hour_min, on='device_id')\\nresult_train = pd.merge(result_train, hour_max, on='device_id')\\nresult_train = pd.merge(result_train, weekday_avg, on='device_id')\\nresult_train = pd.merge(result_train, weekday_med, on='device_id')\\nresult_train = pd.merge(result_train, weekday_min, on='device_id')\\nresult_train = pd.merge(result_train, weekday_max, on='device_id')\\nresult_train = pd.merge(result_train, morning_sum, on='device_id')\\nresult_train = pd.merge(result_train, morning_avg, on='device_id')\\nresult_train = pd.merge(result_train, day_sum, on='device_id')\\nresult_train = pd.merge(result_train, day_avg, on='device_id')\\nresult_train = pd.merge(result_train, evening_sum, on='device_id')\\nresult_train = pd.merge(result_train, evening_avg, on='device_id')\\nresult_train = pd.merge(result_train, night_sum, on='device_id')\\nresult_train = pd.merge(result_train, night_avg, on='device_id')\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "result_train = pd.merge(hour_cnt, hour_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, hour_med, on='device_id')\n",
    "result_train = pd.merge(result_train, hour_min, on='device_id')\n",
    "result_train = pd.merge(result_train, hour_max, on='device_id')\n",
    "result_train = pd.merge(result_train, weekday_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, weekday_med, on='device_id')\n",
    "result_train = pd.merge(result_train, weekday_min, on='device_id')\n",
    "result_train = pd.merge(result_train, weekday_max, on='device_id')\n",
    "result_train = pd.merge(result_train, morning_sum, on='device_id')\n",
    "result_train = pd.merge(result_train, morning_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, day_sum, on='device_id')\n",
    "result_train = pd.merge(result_train, day_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, evening_sum, on='device_id')\n",
    "result_train = pd.merge(result_train, evening_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, night_sum, on='device_id')\n",
    "result_train = pd.merge(result_train, night_avg, on='device_id')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nresult_test = pd.merge(hour_cnt_test, hour_avg_test, on='device_id')\\nresult_test = pd.merge(result_test, hour_med_test, on='device_id')\\nresult_test = pd.merge(result_test, hour_min_test, on='device_id')\\nresult_test = pd.merge(result_test, hour_max_test, on='device_id')\\nresult_test = pd.merge(result_test, weekday_avg_test, on='device_id')\\nresult_test = pd.merge(result_test, weekday_med_test, on='device_id')\\nresult_test = pd.merge(result_test, weekday_min_test, on='device_id')\\nresult_test = pd.merge(result_test, weekday_max_test, on='device_id')\\nresult_test = pd.merge(result_test, morning_sum_test, on='device_id')\\nresult_test = pd.merge(result_test, morning_avg_test, on='device_id')\\nresult_test = pd.merge(result_test, day_sum_test, on='device_id')\\nresult_test = pd.merge(result_test, day_avg_test, on='device_id')\\nresult_test = pd.merge(result_test, evening_sum_test, on='device_id')\\nresult_test = pd.merge(result_test, evening_avg_test, on='device_id')\\nresult_test = pd.merge(result_test, night_sum_test, on='device_id')\\nresult_test = pd.merge(result_test, night_avg_test, on='device_id')\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "result_test = pd.merge(hour_cnt_test, hour_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, hour_med_test, on='device_id')\n",
    "result_test = pd.merge(result_test, hour_min_test, on='device_id')\n",
    "result_test = pd.merge(result_test, hour_max_test, on='device_id')\n",
    "result_test = pd.merge(result_test, weekday_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, weekday_med_test, on='device_id')\n",
    "result_test = pd.merge(result_test, weekday_min_test, on='device_id')\n",
    "result_test = pd.merge(result_test, weekday_max_test, on='device_id')\n",
    "result_test = pd.merge(result_test, morning_sum_test, on='device_id')\n",
    "result_test = pd.merge(result_test, morning_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, day_sum_test, on='device_id')\n",
    "result_test = pd.merge(result_test, day_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, evening_sum_test, on='device_id')\n",
    "result_test = pd.merge(result_test, evening_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, night_sum_test, on='device_id')\n",
    "result_test = pd.merge(result_test, night_avg_test, on='device_id')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_column(table):\n",
    "    labels = sorted(table.unique())\n",
    "    mappings = dict()\n",
    "    for i in range(len(labels)):\n",
    "        mappings[labels[i]] = i\n",
    "    table = table.map(mappings)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#phone_brand['phone+brand'] = phone_brand.phone_brand + phone_brand.device_model\n",
    "#phone_brand = phone_brand.drop(['phone_brand','device_model'],axis=1)\n",
    "#phone_brand = pd.get_dummies(phone_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result_test = pd.merge(result_test, phone_brand, on='device_id')\n",
    "#result_train = pd.merge(result_train, phone_brand, on='device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result_train = pd.merge(result_train, gender_train, on='device_id')\n",
    "#result_train = result_train.drop(['gender','age'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result_train = map_column(result_train, 'group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(2016)\n",
    "\n",
    "def run_xgb(train, test, target, eta=0.1, random_state=0):\n",
    "    #eta = 0.1\n",
    "    max_depth = 3\n",
    "    subsample = 0.7\n",
    "    colsample_bytree = 0.7\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 12,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 20000\n",
    "    early_stopping_rounds = 100\n",
    "    test_size = 0.3\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=test_size, random_state=random_state)\n",
    "    # TODO change split \n",
    "    print('Length train:', X_train.shape[0])\n",
    "    print('Length valid:', X_valid.shape[0])\n",
    "    #y_train = X_train[target]\n",
    "    #y_valid = X_valid[target]\n",
    "    # TODO delete upper code\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "    # sparse matrix ???\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(score, test, prediction):\n",
    "    # Make Submission\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('device_id,F23-,F24-26,F27-28,F29-32,F33-42,F43+,M22-,M23-26,M27-28,M29-31,M32-38,M39+\\n')\n",
    "    total = 0\n",
    "    test_val = test['device_id'].values\n",
    "    for i in range(len(test_val)):\n",
    "        str1 = str(test_val[i])\n",
    "        for j in range(12):\n",
    "            str1 += ',' + str(prediction[i][j])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_group = map_column(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost params. ETA: 0.01, MAX_DEPTH: 3, SUBSAMPLE: 0.7, COLSAMPLE_BY_TREE: 0.7\n",
      "('Length train:', 52251)\n",
      "('Length valid:', 22394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 100 rounds.\n",
      "[0]\ttrain-mlogloss:2.483669\teval-mlogloss:2.483752\n",
      "[1]\ttrain-mlogloss:2.482264\teval-mlogloss:2.482630\n",
      "[2]\ttrain-mlogloss:2.481017\teval-mlogloss:2.481495\n",
      "[3]\ttrain-mlogloss:2.479715\teval-mlogloss:2.480414\n",
      "[4]\ttrain-mlogloss:2.478395\teval-mlogloss:2.479324\n",
      "[5]\ttrain-mlogloss:2.477193\teval-mlogloss:2.478240\n",
      "[6]\ttrain-mlogloss:2.476015\teval-mlogloss:2.477191\n",
      "[7]\ttrain-mlogloss:2.474808\teval-mlogloss:2.476154\n",
      "[8]\ttrain-mlogloss:2.473577\teval-mlogloss:2.475127\n",
      "[9]\ttrain-mlogloss:2.472421\teval-mlogloss:2.474076\n",
      "[10]\ttrain-mlogloss:2.471217\teval-mlogloss:2.473061\n",
      "[11]\ttrain-mlogloss:2.470013\teval-mlogloss:2.472049\n",
      "[12]\ttrain-mlogloss:2.468895\teval-mlogloss:2.471058\n",
      "[13]\ttrain-mlogloss:2.467809\teval-mlogloss:2.470076\n",
      "[14]\ttrain-mlogloss:2.466607\teval-mlogloss:2.469094\n",
      "[15]\ttrain-mlogloss:2.465502\teval-mlogloss:2.468109\n",
      "[16]\ttrain-mlogloss:2.464397\teval-mlogloss:2.467176\n",
      "[17]\ttrain-mlogloss:2.463326\teval-mlogloss:2.466221\n",
      "[18]\ttrain-mlogloss:2.462219\teval-mlogloss:2.465283\n",
      "[19]\ttrain-mlogloss:2.461120\teval-mlogloss:2.464350\n",
      "[20]\ttrain-mlogloss:2.460071\teval-mlogloss:2.463413\n",
      "[21]\ttrain-mlogloss:2.459021\teval-mlogloss:2.462519\n",
      "[22]\ttrain-mlogloss:2.457966\teval-mlogloss:2.461643\n",
      "[23]\ttrain-mlogloss:2.456937\teval-mlogloss:2.460767\n",
      "[24]\ttrain-mlogloss:2.455910\teval-mlogloss:2.459893\n",
      "[25]\ttrain-mlogloss:2.454871\teval-mlogloss:2.459056\n",
      "[26]\ttrain-mlogloss:2.453873\teval-mlogloss:2.458224\n",
      "[27]\ttrain-mlogloss:2.452861\teval-mlogloss:2.457325\n",
      "[28]\ttrain-mlogloss:2.451886\teval-mlogloss:2.456514\n",
      "[29]\ttrain-mlogloss:2.450915\teval-mlogloss:2.455703\n",
      "[30]\ttrain-mlogloss:2.449877\teval-mlogloss:2.454845\n",
      "[31]\ttrain-mlogloss:2.448967\teval-mlogloss:2.454017\n",
      "[32]\ttrain-mlogloss:2.448014\teval-mlogloss:2.453227\n",
      "[33]\ttrain-mlogloss:2.447077\teval-mlogloss:2.452445\n",
      "[34]\ttrain-mlogloss:2.446116\teval-mlogloss:2.451632\n",
      "[35]\ttrain-mlogloss:2.445202\teval-mlogloss:2.450859\n",
      "[36]\ttrain-mlogloss:2.444298\teval-mlogloss:2.450068\n",
      "[37]\ttrain-mlogloss:2.443387\teval-mlogloss:2.449313\n",
      "[38]\ttrain-mlogloss:2.442505\teval-mlogloss:2.448558\n",
      "[39]\ttrain-mlogloss:2.441580\teval-mlogloss:2.447790\n",
      "[40]\ttrain-mlogloss:2.440676\teval-mlogloss:2.447081\n",
      "[41]\ttrain-mlogloss:2.439815\teval-mlogloss:2.446336\n",
      "[42]\ttrain-mlogloss:2.438983\teval-mlogloss:2.445607\n",
      "[43]\ttrain-mlogloss:2.438117\teval-mlogloss:2.444872\n",
      "[44]\ttrain-mlogloss:2.437236\teval-mlogloss:2.444166\n",
      "[45]\ttrain-mlogloss:2.436370\teval-mlogloss:2.443466\n",
      "[46]\ttrain-mlogloss:2.435592\teval-mlogloss:2.442751\n",
      "[47]\ttrain-mlogloss:2.434765\teval-mlogloss:2.442091\n",
      "[48]\ttrain-mlogloss:2.433967\teval-mlogloss:2.441386\n",
      "[49]\ttrain-mlogloss:2.433166\teval-mlogloss:2.440720\n",
      "[50]\ttrain-mlogloss:2.432345\teval-mlogloss:2.440020\n",
      "[51]\ttrain-mlogloss:2.431496\teval-mlogloss:2.439336\n",
      "[52]\ttrain-mlogloss:2.430719\teval-mlogloss:2.438687\n",
      "[53]\ttrain-mlogloss:2.429943\teval-mlogloss:2.438011\n",
      "[54]\ttrain-mlogloss:2.429171\teval-mlogloss:2.437370\n",
      "[55]\ttrain-mlogloss:2.428394\teval-mlogloss:2.436734\n",
      "[56]\ttrain-mlogloss:2.427603\teval-mlogloss:2.436089\n",
      "[57]\ttrain-mlogloss:2.426837\teval-mlogloss:2.435461\n",
      "[58]\ttrain-mlogloss:2.426029\teval-mlogloss:2.434827\n",
      "[59]\ttrain-mlogloss:2.425313\teval-mlogloss:2.434210\n",
      "[60]\ttrain-mlogloss:2.424577\teval-mlogloss:2.433612\n",
      "[61]\ttrain-mlogloss:2.423845\teval-mlogloss:2.433026\n",
      "[62]\ttrain-mlogloss:2.423121\teval-mlogloss:2.432407\n",
      "[63]\ttrain-mlogloss:2.422378\teval-mlogloss:2.431792\n",
      "[64]\ttrain-mlogloss:2.421646\teval-mlogloss:2.431199\n",
      "[65]\ttrain-mlogloss:2.420929\teval-mlogloss:2.430584\n",
      "[66]\ttrain-mlogloss:2.420215\teval-mlogloss:2.430002\n",
      "[67]\ttrain-mlogloss:2.419538\teval-mlogloss:2.429431\n",
      "[68]\ttrain-mlogloss:2.418852\teval-mlogloss:2.428849\n",
      "[69]\ttrain-mlogloss:2.418121\teval-mlogloss:2.428284\n",
      "[70]\ttrain-mlogloss:2.417463\teval-mlogloss:2.427731\n",
      "[71]\ttrain-mlogloss:2.416784\teval-mlogloss:2.427178\n",
      "[72]\ttrain-mlogloss:2.416113\teval-mlogloss:2.426627\n",
      "[73]\ttrain-mlogloss:2.415433\teval-mlogloss:2.426104\n",
      "[74]\ttrain-mlogloss:2.414755\teval-mlogloss:2.425570\n",
      "[75]\ttrain-mlogloss:2.414096\teval-mlogloss:2.425040\n",
      "[76]\ttrain-mlogloss:2.413455\teval-mlogloss:2.424497\n",
      "[77]\ttrain-mlogloss:2.412821\teval-mlogloss:2.423979\n",
      "[78]\ttrain-mlogloss:2.412172\teval-mlogloss:2.423479\n",
      "[79]\ttrain-mlogloss:2.411516\teval-mlogloss:2.422963\n",
      "[80]\ttrain-mlogloss:2.410875\teval-mlogloss:2.422432\n",
      "[81]\ttrain-mlogloss:2.410230\teval-mlogloss:2.421941\n",
      "[82]\ttrain-mlogloss:2.409620\teval-mlogloss:2.421449\n",
      "[83]\ttrain-mlogloss:2.408984\teval-mlogloss:2.420968\n",
      "[84]\ttrain-mlogloss:2.408388\teval-mlogloss:2.420477\n",
      "[85]\ttrain-mlogloss:2.407759\teval-mlogloss:2.419998\n",
      "[86]\ttrain-mlogloss:2.407175\teval-mlogloss:2.419503\n",
      "[87]\ttrain-mlogloss:2.406549\teval-mlogloss:2.419034\n",
      "[88]\ttrain-mlogloss:2.405958\teval-mlogloss:2.418561\n",
      "[89]\ttrain-mlogloss:2.405347\teval-mlogloss:2.418090\n",
      "[90]\ttrain-mlogloss:2.404776\teval-mlogloss:2.417621\n",
      "[91]\ttrain-mlogloss:2.404167\teval-mlogloss:2.417125\n",
      "[92]\ttrain-mlogloss:2.403587\teval-mlogloss:2.416676\n",
      "[93]\ttrain-mlogloss:2.403010\teval-mlogloss:2.416231\n",
      "[94]\ttrain-mlogloss:2.402446\teval-mlogloss:2.415763\n",
      "[95]\ttrain-mlogloss:2.401873\teval-mlogloss:2.415331\n",
      "[96]\ttrain-mlogloss:2.401318\teval-mlogloss:2.414876\n",
      "[97]\ttrain-mlogloss:2.400748\teval-mlogloss:2.414411\n",
      "[98]\ttrain-mlogloss:2.400167\teval-mlogloss:2.413971\n",
      "[99]\ttrain-mlogloss:2.399656\teval-mlogloss:2.413550\n",
      "[100]\ttrain-mlogloss:2.399084\teval-mlogloss:2.413122\n",
      "[101]\ttrain-mlogloss:2.398543\teval-mlogloss:2.412688\n",
      "[102]\ttrain-mlogloss:2.397982\teval-mlogloss:2.412255\n",
      "[103]\ttrain-mlogloss:2.397436\teval-mlogloss:2.411848\n",
      "[104]\ttrain-mlogloss:2.396898\teval-mlogloss:2.411400\n"
     ]
    }
   ],
   "source": [
    "res, score = run_xgb(X[:train_data.shape[0]], X[train_data.shape[0]:], map_group, eta=0.02, random_state=0)\n",
    "print score\n",
    "#create_submission(score, result_test, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Writing submission: ', 'submission_2.31748792478_2016-08-16-14-43.csv')\n"
     ]
    }
   ],
   "source": [
    "create_submission(score, gender_test, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.cross_validation #импортируем кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc = StandardScaler()\n",
    "#scaled_train = sc.fit_transform(result_train[result_train.columns.difference(['group','device_id'])])\n",
    "#scaled_test = sc.fit_transform(result_test[result_test.columns.difference(['group'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import time\n",
    "#import datetime\n",
    "\n",
    "#bag_score = []#список результатов\n",
    "#c_est = [10**-2,10**-1,1,10,100,1000]#значения C для перебора\n",
    "#lr_models = []\n",
    "#for c in c_est:\n",
    "#    start_time = datetime.datetime.now()\n",
    "#    logr = LogisticRegression(penalty='l2',C=c,tol=0.000001,verbose=True)#логистическая регрессия\n",
    "#    #lr_models.append(logr.fit(scaled_train_bag, features_target))#обучаем класификатор\n",
    "#    bag_score.append(sklearn.cross_validation.cross_val_score(logr, scaled_train, result_train['group'].values,cv=3, scoring='log_loss').mean())\n",
    "#    #к списку результатов добавляем средний получившийся на кросс-валидации результат по roc_auc score\n",
    "#    print bag_score\n",
    "#    print 'Time elapsed for c =', c,':', datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print bag_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
