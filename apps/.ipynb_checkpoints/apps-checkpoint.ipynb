{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_train = pd.read_csv('gender_age_train.csv')\n",
    "gender_test = pd.read_csv('gender_age_test.csv')\n",
    "phone_brand = pd.read_csv('phone_brand_device_model.csv')\n",
    "app_events = pd.read_csv('app_events.csv', dtype={'app_id': np.str})\n",
    "app_labels = pd.read_csv('app_labels.csv')\n",
    "labels = pd.read_csv('label_categories.csv')\n",
    "events = pd.read_csv('events_new.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_ev = app_events.drop(['is_installed', 'is_active'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9221156934682287334</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9220899153371182692</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9218487885271516150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9218487885267037129</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9218310540360546691</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id  event_id\n",
       "0 -9221156934682287334        21\n",
       "1 -9220899153371182692        25\n",
       "2 -9218487885271516150         2\n",
       "3 -9218487885267037129         6\n",
       "4 -9218310540360546691        38"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_cnt = app_ev.groupby('app_id', as_index=False)['event_id'].count()\n",
    "app_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_apps = app_cnt[app_cnt.event_id>app_cnt.quantile(.99).event_id].app_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34061.559999999998"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_cnt.quantile(.99).event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32473067, 2)\n",
      "(19213345, 2)\n"
     ]
    }
   ],
   "source": [
    "print app_ev.shape\n",
    "print app_ev[app_ev.app_id.isin(common_apps)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8318af7aee2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapp_bag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp_ev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapp_ev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_apps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'app_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/core/reshape.pyc\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             dummy = _get_dummies_1d(data[col], prefix=pre, prefix_sep=sep,\n\u001b[1;32m   1092\u001b[0m                                     \u001b[0mdummy_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy_na\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m                                     drop_first=drop_first)\n\u001b[0m\u001b[1;32m   1094\u001b[0m             \u001b[0mwith_dummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/core/reshape.pyc\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         \u001b[0mdummy_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make it like a event-id - text with the app_ids (e.g. \"100 101 10020 ...\")\n",
    "# then use bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(events, app_events, on='event_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phone_brand.drop_duplicates(subset='device_id',keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.is_morning = data.is_morning.astype(int)\n",
    "data.is_night = data.is_night.astype(int)\n",
    "data.is_day = data.is_day.astype(int)\n",
    "data.is_evening = data.is_evening.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(gender_train, data, on='device_id', how='left')\n",
    "test_data = pd.merge(gender_test, data, on='device_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, phone_brand, on='device_id')\n",
    "test_data = pd.merge(test_data, phone_brand, on='device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(-1)\n",
    "test_data = test_data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_events_sum = app_events.groupby(['event_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_cnt = app_events.groupby(['event_id'], as_index=False)['app_id'].count()\n",
    "installed_sum = app_events.groupby(['event_id'], as_index=False)['is_installed'].sum()\n",
    "active_sum = app_events.groupby(['event_id'], as_index=False)['is_active'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_data_med = pd.merge(app_cnt, installed_sum, on=['event_id'])\n",
    "app_data = pd.merge(app_data_med, active_sum, on=['event_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_data['active_share'] = app_data.is_active/app_data.app_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['gender','age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels = labels.fillna('no_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count devices in events\n",
    "hour_cnt = train_data.groupby(['device_id'], as_index=False)['hour'].count().rename(columns={'hour':'device_cnt'})\n",
    "# hour activities\n",
    "hour_avg = train_data.groupby(['device_id'], as_index=False)['hour'].mean().rename(columns={'hour':'hour_avg'})\n",
    "hour_med = train_data.groupby(['device_id'], as_index=False)['hour'].median().rename(columns={'hour':'hour_med'})\n",
    "hour_min = train_data.groupby(['device_id'], as_index=False)['hour'].min().rename(columns={'hour':'hour_min'})\n",
    "hour_max = train_data.groupby(['device_id'], as_index=False)['hour'].max().rename(columns={'hour':'hour_max'})\n",
    "# weekday activities\n",
    "weekday_avg = train_data.groupby(['device_id'], as_index=False)['weekday'].mean().rename(columns={'weekday':'weekday_avg'})\n",
    "weekday_med = train_data.groupby(['device_id'], as_index=False)['weekday'].median().rename(columns={'weekday':'weekday_med'})\n",
    "weekday_min = train_data.groupby(['device_id'], as_index=False)['weekday'].min().rename(columns={'weekday':'weekday_min'})\n",
    "weekday_max = train_data.groupby(['device_id'], as_index=False)['weekday'].max().rename(columns={'weekday':'weekday_max'})\n",
    "# part of day activities\n",
    "morning_sum = train_data.groupby(['device_id'], as_index=False)['is_morning'].sum().rename(columns={'is_morning':'morning_sum'})\n",
    "morning_avg = train_data.groupby(['device_id'], as_index=False)['is_morning'].mean().rename(columns={'is_morning':'morning_avg'})\n",
    "day_sum = train_data.groupby(['device_id'], as_index=False)['is_day'].sum().rename(columns={'is_morning':'day_sum'})\n",
    "day_avg = train_data.groupby(['device_id'], as_index=False)['is_day'].mean().rename(columns={'is_morning':'day_avg'})\n",
    "night_sum = train_data.groupby(['device_id'], as_index=False)['is_night'].sum().rename(columns={'is_night':'night_sum'})\n",
    "night_avg = train_data.groupby(['device_id'], as_index=False)['is_night'].mean().rename(columns={'is_night':'night_avg'})\n",
    "evening_sum = train_data.groupby(['device_id'], as_index=False)['is_evening'].sum().rename(columns={'is_evening':'evening_sum'})\n",
    "evening_avg = train_data.groupby(['device_id'], as_index=False)['is_evening'].mean().rename(columns={'is_evening':'evening_avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count devices in events\n",
    "hour_cnt_test = test_data.groupby(['device_id'], as_index=False)['hour'].count().rename(columns={'hour':'device_cnt'})\n",
    "# hour activities\n",
    "hour_avg_test = test_data.groupby(['device_id'], as_index=False)['hour'].mean().rename(columns={'hour':'hour_avg'})\n",
    "hour_med_test = test_data.groupby(['device_id'], as_index=False)['hour'].median().rename(columns={'hour':'hour_med'})\n",
    "hour_min_test = test_data.groupby(['device_id'], as_index=False)['hour'].min().rename(columns={'hour':'hour_min'})\n",
    "hour_max_test = test_data.groupby(['device_id'], as_index=False)['hour'].max().rename(columns={'hour':'hour_max'})\n",
    "# weekday activities\n",
    "weekday_avg_test = test_data.groupby(['device_id'], as_index=False)['weekday'].mean().rename(columns={'weekday':'weekday_avg'})\n",
    "weekday_med_test = test_data.groupby(['device_id'], as_index=False)['weekday'].median().rename(columns={'weekday':'weekday_med'})\n",
    "weekday_min_test = test_data.groupby(['device_id'], as_index=False)['weekday'].min().rename(columns={'weekday':'weekday_min'})\n",
    "weekday_max_test = test_data.groupby(['device_id'], as_index=False)['weekday'].max().rename(columns={'weekday':'weekday_max'})\n",
    "# part of day activities\n",
    "morning_sum_test = test_data.groupby(['device_id'], as_index=False)['is_morning'].sum().rename(columns={'is_morning':'morning_sum'})\n",
    "morning_avg_test = test_data.groupby(['device_id'], as_index=False)['is_morning'].mean().rename(columns={'is_morning':'morning_avg'})\n",
    "day_sum_test = test_data.groupby(['device_id'], as_index=False)['is_day'].sum().rename(columns={'is_morning':'day_sum'})\n",
    "day_avg_test = test_data.groupby(['device_id'], as_index=False)['is_day'].mean().rename(columns={'is_morning':'day_avg'})\n",
    "night_sum_test = test_data.groupby(['device_id'], as_index=False)['is_night'].sum().rename(columns={'is_night':'night_sum'})\n",
    "night_avg_test = test_data.groupby(['device_id'], as_index=False)['is_night'].mean().rename(columns={'is_night':'night_avg'})\n",
    "evening_sum_test = test_data.groupby(['device_id'], as_index=False)['is_evening'].sum().rename(columns={'is_evening':'evening_sum'})\n",
    "evening_avg_test = test_data.groupby(['device_id'], as_index=False)['is_evening'].mean().rename(columns={'is_evening':'evening_avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_train = pd.merge(hour_cnt, hour_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, hour_med, on='device_id')\n",
    "result_train = pd.merge(result_train, hour_min, on='device_id')\n",
    "result_train = pd.merge(result_train, hour_max, on='device_id')\n",
    "result_train = pd.merge(result_train, weekday_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, weekday_med, on='device_id')\n",
    "result_train = pd.merge(result_train, weekday_min, on='device_id')\n",
    "result_train = pd.merge(result_train, weekday_max, on='device_id')\n",
    "result_train = pd.merge(result_train, morning_sum, on='device_id')\n",
    "result_train = pd.merge(result_train, morning_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, day_sum, on='device_id')\n",
    "result_train = pd.merge(result_train, day_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, evening_sum, on='device_id')\n",
    "result_train = pd.merge(result_train, evening_avg, on='device_id')\n",
    "result_train = pd.merge(result_train, night_sum, on='device_id')\n",
    "result_train = pd.merge(result_train, night_avg, on='device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_test = pd.merge(hour_cnt_test, hour_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, hour_med_test, on='device_id')\n",
    "result_test = pd.merge(result_test, hour_min_test, on='device_id')\n",
    "result_test = pd.merge(result_test, hour_max_test, on='device_id')\n",
    "result_test = pd.merge(result_test, weekday_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, weekday_med_test, on='device_id')\n",
    "result_test = pd.merge(result_test, weekday_min_test, on='device_id')\n",
    "result_test = pd.merge(result_test, weekday_max_test, on='device_id')\n",
    "result_test = pd.merge(result_test, morning_sum_test, on='device_id')\n",
    "result_test = pd.merge(result_test, morning_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, day_sum_test, on='device_id')\n",
    "result_test = pd.merge(result_test, day_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, evening_sum_test, on='device_id')\n",
    "result_test = pd.merge(result_test, evening_avg_test, on='device_id')\n",
    "result_test = pd.merge(result_test, night_sum_test, on='device_id')\n",
    "result_test = pd.merge(result_test, night_avg_test, on='device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_column(table, f):\n",
    "    labels = sorted(table[f].unique())\n",
    "    mappings = dict()\n",
    "    for i in range(len(labels)):\n",
    "        mappings[labels[i]] = i\n",
    "    table = table.replace({f: mappings})\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phone_brand['phone+brand'] = phone_brand.phone_brand + phone_brand.device_model\n",
    "phone_brand = phone_brand.drop(['phone_brand','device_model'],axis=1)\n",
    "phone_brand = pd.get_dummies(phone_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test = pd.merge(result_test, phone_brand, on='device_id')\n",
    "result_train = pd.merge(result_train, phone_brand, on='device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_train = pd.merge(result_train, gender_train, on='device_id')\n",
    "result_train = result_train.drop(['gender','age'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_train = map_column(result_train, 'group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(2016)\n",
    "\n",
    "def run_xgb(train, test, features, target, eta=0.1, random_state=0):\n",
    "    #eta = 0.1\n",
    "    max_depth = 3\n",
    "    subsample = 0.7\n",
    "    colsample_bytree = 0.7\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 12,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 2000\n",
    "    early_stopping_rounds = 100\n",
    "    test_size = 0.3\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(score, test, prediction):\n",
    "    # Make Submission\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('device_id,F23-,F24-26,F27-28,F29-32,F33-42,F43+,M22-,M23-26,M27-28,M29-31,M32-38,M39+\\n')\n",
    "    total = 0\n",
    "    test_val = test['device_id'].values\n",
    "    for i in range(len(test_val)):\n",
    "        str1 = str(test_val[i])\n",
    "        for j in range(12):\n",
    "            str1 += ',' + str(prediction[i][j])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#res, score = run_xgb(result_train, result_test, result_train.columns.values[:len(result_train.columns)-1], 'group', eta=0.01, random_state=0)\n",
    "#print score\n",
    "#create_submission(score, result_test, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create_submission(score, result_test, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.cross_validation #импортируем кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "scaled_train = sc.fit_transform(result_train[result_train.columns.difference(['group','device_id'])])\n",
    "scaled_test = sc.fit_transform(result_test[result_test.columns.difference(['group'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "bag_score = []#список результатов\n",
    "c_est = [10**-2,10**-1,1,10,100,1000]#значения C для перебора\n",
    "lr_models = []\n",
    "for c in c_est:\n",
    "    start_time = datetime.datetime.now()\n",
    "    logr = LogisticRegression(penalty='l2',C=c,tol=0.000001,verbose=True)#логистическая регрессия\n",
    "    #lr_models.append(logr.fit(scaled_train_bag, features_target))#обучаем класификатор\n",
    "    bag_score.append(sklearn.cross_validation.cross_val_score(logr, scaled_train, result_train['group'].values,cv=3, scoring='log_loss').mean())\n",
    "    #к списку результатов добавляем средний получившийся на кросс-валидации результат по roc_auc score\n",
    "    print bag_score\n",
    "    print 'Time elapsed for c =', c,':', datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print bag_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
