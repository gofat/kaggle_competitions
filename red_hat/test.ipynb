{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('act_train.csv', parse_dates = ['date'])\n",
    "test = pd.read_csv('act_test.csv', parse_dates = ['date'])\n",
    "people = pd.read_csv('people.csv', parse_dates = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_1734928</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_2434093</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  people_id   activity_id       date activity_category char_1 char_2 char_3  \\\n",
       "0   ppl_100  act2_1734928 2023-08-26            type 4    NaN    NaN    NaN   \n",
       "1   ppl_100  act2_2434093 2022-09-27            type 2    NaN    NaN    NaN   \n",
       "\n",
       "  char_4 char_5 char_6 char_7 char_8 char_9  char_10  outcome  \n",
       "0    NaN    NaN    NaN    NaN    NaN    NaN  type 76        0  \n",
       "1    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100004</td>\n",
       "      <td>act1_249281</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 10</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 6</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 7</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100004</td>\n",
       "      <td>act2_230855</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>type 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    people_id  activity_id       date activity_category  char_1   char_2  \\\n",
       "0  ppl_100004  act1_249281 2022-07-20            type 1  type 5  type 10   \n",
       "1  ppl_100004  act2_230855 2022-07-20            type 5     NaN      NaN   \n",
       "\n",
       "   char_3  char_4  char_5  char_6  char_7  char_8  char_9   char_10  \n",
       "0  type 5  type 1  type 6  type 1  type 1  type 7  type 4       NaN  \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN  type 682  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>char_1</th>\n",
       "      <th>group_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>date</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>...</th>\n",
       "      <th>char_29</th>\n",
       "      <th>char_30</th>\n",
       "      <th>char_31</th>\n",
       "      <th>char_32</th>\n",
       "      <th>char_33</th>\n",
       "      <th>char_34</th>\n",
       "      <th>char_35</th>\n",
       "      <th>char_36</th>\n",
       "      <th>char_37</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 17304</td>\n",
       "      <td>type 2</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100002</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 8688</td>\n",
       "      <td>type 3</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>type 28</td>\n",
       "      <td>type 9</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    people_id  char_1      group_1  char_2       date   char_3  char_4  \\\n",
       "0     ppl_100  type 2  group 17304  type 2 2021-06-29   type 5  type 5   \n",
       "1  ppl_100002  type 2   group 8688  type 3 2021-01-06  type 28  type 9   \n",
       "\n",
       "   char_5  char_6   char_7   ...   char_29 char_30 char_31 char_32 char_33  \\\n",
       "0  type 5  type 3  type 11   ...     False    True    True   False   False   \n",
       "1  type 5  type 3  type 11   ...     False    True    True    True    True   \n",
       "\n",
       "  char_34 char_35 char_36 char_37 char_38  \n",
       "0    True    True    True   False      36  \n",
       "1    True    True    True   False      76  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the test IDs for Kaggle submission\n",
    "test_ids = test['activity_id']\n",
    "\n",
    "def preprocess_acts(data, train_set=True):\n",
    "    \n",
    "    # Getting rid of data feature for now\n",
    "    data = data.drop(['date', 'activity_id'], axis=1)\n",
    "    if(train_set):\n",
    "        data = data.drop(['outcome'], axis=1)\n",
    "    \n",
    "    ## Split off _ from people_id\n",
    "    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n",
    "    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n",
    "    \n",
    "    columns = list(data.columns)\n",
    "    \n",
    "    # Convert strings to ints\n",
    "    for col in columns[1:]:\n",
    "        data[col] = data[col].fillna('type -999')\n",
    "        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n",
    "        data[col] = pd.to_numeric(data[col]).astype(int)\n",
    "    return data\n",
    "\n",
    "def preprocess_people(data):\n",
    "    \n",
    "    # TODO refactor this duplication\n",
    "    data = data.drop(['date'], axis=1)\n",
    "    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n",
    "    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n",
    "    \n",
    "    #  Values in the people df is Booleans and Strings    \n",
    "    columns = list(data.columns)\n",
    "    bools = columns[11:]\n",
    "    strings = columns[1:11]\n",
    "    \n",
    "    for col in bools:\n",
    "        data[col] = pd.to_numeric(data[col]).astype(int)        \n",
    "    for col in strings:\n",
    "        data[col] = data[col].fillna('type -999')\n",
    "        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n",
    "        data[col] = pd.to_numeric(data[col]).astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess each df\n",
    "peeps = preprocess_people(people)\n",
    "actions_train = preprocess_acts(train)\n",
    "actions_test = preprocess_acts(test, train_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1_x</th>\n",
       "      <th>char_2_x</th>\n",
       "      <th>char_3_x</th>\n",
       "      <th>char_4_x</th>\n",
       "      <th>char_5_x</th>\n",
       "      <th>char_6_x</th>\n",
       "      <th>char_7_x</th>\n",
       "      <th>char_8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>char_29</th>\n",
       "      <th>char_30</th>\n",
       "      <th>char_31</th>\n",
       "      <th>char_32</th>\n",
       "      <th>char_33</th>\n",
       "      <th>char_34</th>\n",
       "      <th>char_35</th>\n",
       "      <th>char_36</th>\n",
       "      <th>char_37</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>867017</th>\n",
       "      <td>247268</td>\n",
       "      <td>2</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459583</th>\n",
       "      <td>342471</td>\n",
       "      <td>2</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832793</th>\n",
       "      <td>39806</td>\n",
       "      <td>5</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94187</th>\n",
       "      <td>108295</td>\n",
       "      <td>5</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456021</th>\n",
       "      <td>341775</td>\n",
       "      <td>4</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         people_id  activity_category  char_1_x  char_2_x  char_3_x  char_4_x  \\\n",
       "867017      247268                  2      -999      -999      -999      -999   \n",
       "1459583     342471                  2      -999      -999      -999      -999   \n",
       "1832793      39806                  5      -999      -999      -999      -999   \n",
       "94187       108295                  5      -999      -999      -999      -999   \n",
       "1456021     341775                  4      -999      -999      -999      -999   \n",
       "\n",
       "         char_5_x  char_6_x  char_7_x  char_8_x   ...     char_29  char_30  \\\n",
       "867017       -999      -999      -999      -999   ...           0        0   \n",
       "1459583      -999      -999      -999      -999   ...           0        0   \n",
       "1832793      -999      -999      -999      -999   ...           0        0   \n",
       "94187        -999      -999      -999      -999   ...           0        0   \n",
       "1456021      -999      -999      -999      -999   ...           0        0   \n",
       "\n",
       "         char_31  char_32  char_33  char_34  char_35  char_36  char_37  \\\n",
       "867017         0        0        0        0        0        0        0   \n",
       "1459583        0        0        0        0        0        0        0   \n",
       "1832793        1        0        1        0        0        0        0   \n",
       "94187          0        0        0        0        0        0        0   \n",
       "1456021        0        0        0        1        0        0        0   \n",
       "\n",
       "         char_38  \n",
       "867017        76  \n",
       "1459583       69  \n",
       "1832793       90  \n",
       "94187         84  \n",
       "1456021       85  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merege into a unified table\n",
    "\n",
    "# Training \n",
    "features = actions_train.merge(peeps, how='left', on='people_id')\n",
    "labels = train['outcome']\n",
    "\n",
    "# Testing\n",
    "df_test = actions_test.merge(peeps, how='left', on='people_id')\n",
    "\n",
    "# Check it out...\n",
    "features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fec6d7e6f10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEDCAYAAAASpvJbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec6d7e6990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.char_38.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fec6bad8f90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEDCAYAAAASpvJbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRZJUhYEiSarCQJEkVfF/AdURmGQ6+QvBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec6bad7110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.char_38.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label kfold on people_id works bad :(\n",
    "# and statified kfold too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = features[['char_38','group_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f['quadr_38'] = f['char_38']**2\n",
    "#f['quadr_gr_1'] = f['group_1']**2\n",
    "f['ln_38'] = f['char_38'].apply(lambda x: np.log(x+0.01))\n",
    "f['ln_gr_1'] = f['group_1'].apply(lambda x: np.log(x+0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f[f['ln_38']==-np.inf] = -100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„–  1  fold for value : 2\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2695            1.16m\n",
      "         2           1.1839            1.17m\n",
      "         3           1.1126            1.18m\n",
      "         4           1.0527            1.16m\n",
      "         5           1.0016            1.15m\n",
      "         6           0.9581            1.13m\n",
      "         7           0.9210            1.12m\n",
      "         8           0.8886            1.10m\n",
      "         9           0.8609            1.09m\n",
      "        10           0.8366            1.07m\n",
      "        20           0.7107           54.56s\n",
      "        30           0.6667           44.98s\n",
      "        40           0.6485           35.91s\n",
      "        50           0.6390           26.69s\n",
      "        60           0.6312           17.48s\n",
      "        70           0.6250            8.26s\n",
      "â„–  2  fold for value : 2\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2702            1.29m\n",
      "         2           1.1848            1.26m\n",
      "         3           1.1138            1.23m\n",
      "         4           1.0541            1.22m\n",
      "         5           1.0035            1.20m\n",
      "         6           0.9603            1.17m\n",
      "         7           0.9233            1.16m\n",
      "         8           0.8913            1.14m\n",
      "         9           0.8637            1.11m\n",
      "        10           0.8398            1.10m\n",
      "        20           0.7132           56.20s\n",
      "        30           0.6697           46.46s\n",
      "        40           0.6490           37.12s\n",
      "        50           0.6395           27.60s\n",
      "        60           0.6308           18.13s\n",
      "        70           0.6239            8.59s\n",
      "â„–  3  fold for value : 2\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2685            1.18m\n",
      "         2           1.1828            1.16m\n",
      "         3           1.1114            1.16m\n",
      "         4           1.0513            1.16m\n",
      "         5           1.0004            1.15m\n",
      "         6           0.9570            1.13m\n",
      "         7           0.9198            1.12m\n",
      "         8           0.8877            1.11m\n",
      "         9           0.8600            1.09m\n",
      "        10           0.8358            1.07m\n",
      "        20           0.7078           54.96s\n",
      "        30           0.6673           45.62s\n",
      "        40           0.6488           36.51s\n",
      "        50           0.6388           27.24s\n",
      "        60           0.6327           17.87s\n",
      "        70           0.6274            8.46s\n",
      "(2, 0.85417421449834707)\n",
      "â„–  1  fold for value : 3\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2695            1.22m\n",
      "         2           1.1839            1.22m\n",
      "         3           1.1126            1.20m\n",
      "         4           1.0527            1.19m\n",
      "         5           1.0016            1.17m\n",
      "         6           0.9581            1.15m\n",
      "         7           0.9210            1.15m\n",
      "         8           0.8886            1.13m\n",
      "         9           0.8609            1.11m\n",
      "        10           0.8366            1.10m\n",
      "        20           0.7107           55.93s\n",
      "        30           0.6667           46.19s\n",
      "        40           0.6485           36.94s\n",
      "        50           0.6390           27.43s\n",
      "        60           0.6312           17.97s\n",
      "        70           0.6250            8.49s\n",
      "â„–  2  fold for value : 3\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2702            1.23m\n",
      "         2           1.1848            1.22m\n",
      "         3           1.1138            1.20m\n",
      "         4           1.0541            1.19m\n",
      "         5           1.0035            1.18m\n",
      "         6           0.9603            1.16m\n",
      "         7           0.9233            1.14m\n",
      "         8           0.8913            1.13m\n",
      "         9           0.8637            1.11m\n",
      "        10           0.8398            1.10m\n",
      "        20           0.7132           56.37s\n",
      "        30           0.6697           46.69s\n",
      "        40           0.6490           37.22s\n",
      "        50           0.6395           27.68s\n",
      "        60           0.6308           18.15s\n",
      "        70           0.6239            8.60s\n",
      "â„–  3  fold for value : 3\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2685            1.15m\n",
      "         2           1.1828            1.15m\n",
      "         3           1.1114            1.18m\n",
      "         4           1.0513            1.17m\n",
      "         5           1.0004            1.15m\n",
      "         6           0.9570            1.16m\n",
      "         7           0.9198            1.14m\n",
      "         8           0.8877            1.12m\n",
      "         9           0.8600            1.11m\n",
      "        10           0.8358            1.09m\n",
      "        20           0.7078           55.64s\n",
      "        30           0.6673           46.07s\n",
      "        40           0.6488           36.96s\n",
      "        50           0.6388           27.51s\n",
      "        60           0.6327           18.02s\n",
      "        70           0.6274            8.51s\n",
      "(3, 0.85417421449834707)\n",
      "â„–  1  fold for value : 4\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2695            1.19m\n",
      "         2           1.1839            1.19m\n",
      "         3           1.1126            1.18m\n",
      "         4           1.0527            1.17m\n",
      "         5           1.0016            1.15m\n",
      "         6           0.9581            1.14m\n",
      "         7           0.9210            1.12m\n",
      "         8           0.8886            1.11m\n",
      "         9           0.8609            1.10m\n",
      "        10           0.8366            1.08m\n",
      "        20           0.7107           55.27s\n",
      "        30           0.6667           45.75s\n",
      "        40           0.6485           36.67s\n",
      "        50           0.6390           27.29s\n",
      "        60           0.6312           17.89s\n",
      "        70           0.6250            8.46s\n",
      "â„–  2  fold for value : 4\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2702            1.23m\n",
      "         2           1.1848            1.21m\n",
      "         3           1.1138            1.21m\n",
      "         4           1.0541            1.19m\n",
      "         5           1.0035            1.17m\n",
      "         6           0.9603            1.15m\n",
      "         7           0.9233            1.14m\n",
      "         8           0.8913            1.12m\n",
      "         9           0.8637            1.10m\n",
      "        10           0.8398            1.09m\n",
      "        20           0.7132           56.12s\n",
      "        30           0.6697           46.71s\n",
      "        40           0.6490           37.31s\n",
      "        50           0.6395           27.76s\n",
      "        60           0.6308           18.22s\n",
      "        70           0.6239            8.62s\n",
      "â„–  3  fold for value : 4\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2685            1.14m\n",
      "         2           1.1828            1.15m\n",
      "         3           1.1114            1.15m\n",
      "         4           1.0513            1.15m\n",
      "         5           1.0004            1.14m\n",
      "         6           0.9570            1.13m\n",
      "         7           0.9198            1.11m\n",
      "         8           0.8877            1.10m\n",
      "         9           0.8600            1.09m\n",
      "        10           0.8358            1.07m\n",
      "        20           0.7078           55.45s\n",
      "        30           0.6673           46.09s\n",
      "        40           0.6488           36.81s\n",
      "        50           0.6388           27.40s\n",
      "        60           0.6327           17.95s\n",
      "        70           0.6274            8.49s\n",
      "(4, 0.85417626737948471)\n",
      "â„–  1  fold for value : 5\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2695            1.20m\n",
      "         2           1.1839            1.18m\n",
      "         3           1.1126            1.17m\n",
      "         4           1.0527            1.14m\n",
      "         5           1.0016            1.13m\n",
      "         6           0.9581            1.12m\n",
      "         7           0.9210            1.10m\n",
      "         8           0.8886            1.09m\n",
      "         9           0.8609            1.08m\n",
      "        10           0.8366            1.06m\n",
      "        20           0.7107           54.32s\n",
      "        30           0.6667           44.85s\n",
      "        40           0.6485           36.02s\n",
      "        50           0.6390           26.73s\n",
      "        60           0.6312           17.49s\n",
      "        70           0.6250            8.26s\n",
      "â„–  2  fold for value : 5\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2702            1.23m\n",
      "         2           1.1848            1.22m\n",
      "         3           1.1138            1.19m\n",
      "         4           1.0541            1.18m\n",
      "         5           1.0035            1.16m\n",
      "         6           0.9603            1.14m\n",
      "         7           0.9233            1.12m\n",
      "         8           0.8913            1.11m\n",
      "         9           0.8637            1.09m\n",
      "        10           0.8398            1.07m\n",
      "        20           0.7132           54.85s\n",
      "        30           0.6697           45.54s\n",
      "        40           0.6490           36.38s\n",
      "        50           0.6395           27.03s\n",
      "        60           0.6308           17.72s\n",
      "        70           0.6239            8.39s\n",
      "â„–  3  fold for value : 5\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2685            1.17m\n",
      "         2           1.1828            1.17m\n",
      "         3           1.1114            1.17m\n",
      "         4           1.0513            1.17m\n",
      "         5           1.0004            1.16m\n",
      "         6           0.9570            1.16m\n",
      "         7           0.9198            1.14m\n",
      "         8           0.8877            1.13m\n",
      "         9           0.8600            1.12m\n",
      "        10           0.8358            1.10m\n",
      "        20           0.7078           56.39s\n",
      "        30           0.6673           46.52s\n",
      "        40           0.6488           37.09s\n",
      "        50           0.6388           27.50s\n",
      "        60           0.6327           17.99s\n",
      "        70           0.6274            8.50s\n",
      "(5, 0.85417462218669693)\n",
      "â„–  1  fold for value : 6\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2695            1.18m\n",
      "         2           1.1839            1.18m\n",
      "         3           1.1126            1.17m\n",
      "         4           1.0527            1.16m\n",
      "         5           1.0016            1.16m\n",
      "         6           0.9581            1.14m\n",
      "         7           0.9210            1.13m\n",
      "         8           0.8886            1.12m\n",
      "         9           0.8609            1.10m\n",
      "        10           0.8366            1.09m\n",
      "        20           0.7107           55.48s\n",
      "        30           0.6667           45.92s\n",
      "        40           0.6485           36.61s\n",
      "        50           0.6390           27.18s\n",
      "        60           0.6312           17.79s\n",
      "        70           0.6250            8.41s\n",
      "â„–  2  fold for value : 6\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2702            1.23m\n",
      "         2           1.1848            1.22m\n",
      "         3           1.1138            1.20m\n",
      "         4           1.0541            1.18m\n",
      "         5           1.0035            1.17m\n",
      "         6           0.9603            1.15m\n",
      "         7           0.9233            1.14m\n",
      "         8           0.8913            1.12m\n",
      "         9           0.8637            1.10m\n",
      "        10           0.8398            1.09m\n",
      "        20           0.7132           55.74s\n",
      "        30           0.6697           46.38s\n",
      "        40           0.6490           37.02s\n",
      "        50           0.6395           27.55s\n",
      "        60           0.6308           18.09s\n",
      "        70           0.6239            8.58s\n",
      "â„–  3  fold for value : 6\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2685            1.16m\n",
      "         2           1.1828            1.14m\n",
      "         3           1.1114            1.15m\n",
      "         4           1.0513            1.14m\n",
      "         5           1.0004            1.13m\n",
      "         6           0.9570            1.11m\n",
      "         7           0.9198            1.09m\n",
      "         8           0.8877            1.08m\n",
      "         9           0.8600            1.06m\n",
      "        10           0.8358            1.05m\n",
      "        20           0.7078           54.59s\n",
      "        30           0.6673           45.14s\n",
      "        40           0.6488           36.09s\n",
      "        50           0.6388           26.93s\n",
      "        60           0.6327           17.64s\n",
      "        70           0.6274            8.35s\n",
      "(6, 0.85417421449834707)\n",
      "â„–  1  fold for value : 7\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2695            1.27m\n",
      "         2           1.1839            1.26m\n",
      "         3           1.1126            1.23m\n",
      "         4           1.0527            1.21m\n",
      "         5           1.0016            1.20m\n",
      "         6           0.9581            1.18m\n",
      "         7           0.9210            1.16m\n",
      "         8           0.8886            1.14m\n",
      "         9           0.8609            1.13m\n",
      "        10           0.8366            1.11m\n",
      "        20           0.7107           56.72s\n",
      "        30           0.6667           46.80s\n",
      "        40           0.6485           37.40s\n",
      "        50           0.6390           27.79s\n",
      "        60           0.6312           18.20s\n",
      "        70           0.6250            8.61s\n",
      "â„–  2  fold for value : 7\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2702            1.25m\n",
      "         2           1.1848            1.22m\n",
      "         3           1.1138            1.22m\n",
      "         4           1.0541            1.21m\n",
      "         5           1.0035            1.19m\n",
      "         6           0.9603            1.17m\n",
      "         7           0.9233            1.15m\n",
      "         8           0.8913            1.14m\n",
      "         9           0.8637            1.11m\n",
      "        10           0.8398            1.10m\n",
      "        20           0.7132           56.13s\n",
      "        30           0.6697           46.50s\n",
      "        40           0.6490           37.11s\n",
      "        50           0.6395           27.57s\n",
      "        60           0.6308           18.08s\n",
      "        70           0.6239            8.54s\n",
      "â„–  3  fold for value : 7\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2685            1.21m\n",
      "         2           1.1828            1.19m\n",
      "         3           1.1114            1.20m\n",
      "         4           1.0513            1.20m\n",
      "         5           1.0004            1.18m\n",
      "         6           0.9570            1.17m\n",
      "         7           0.9198            1.16m\n",
      "         8           0.8877            1.14m\n",
      "         9           0.8600            1.13m\n",
      "        10           0.8358            1.11m\n",
      "        20           0.7078           57.54s\n",
      "        30           0.6673           47.76s\n",
      "        40           0.6488           38.31s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8c71d5118385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m79\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#lr.fit(train_feat, train_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m#pred = lr.predict(check_feat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1025\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1078\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1079\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 784\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#kf = StratifiedKFold(train_data['char_38'], n_folds=3)\n",
    "kf = StratifiedKFold(f['char_38'], n_folds=3)\n",
    "#for i in [10**-i for i in range(-10,10)]:\n",
    "for i in range(2,10,1):\n",
    "    score = []\n",
    "    n = 1\n",
    "    for train_index, cv_index in kf:\n",
    "        print 'â„– ', n,' fold for value :', i\n",
    "        #train_data, check_data = features.ix[train_index], features.ix[cv_index]\n",
    "        train_data, check_data = f.ix[train_index], f.ix[cv_index]\n",
    "        train_labels, check_labels = labels[train_index], labels[cv_index]\n",
    "        \n",
    "        #lr = LogisticRegression(C=i)\n",
    "        gb = GradientBoostingClassifier(n_estimators=79, max_depth=4, verbose=1, min_samples_split=i)\n",
    "        #lr.fit(train_feat, train_labels)\n",
    "        gb.fit(train_data, train_labels)\n",
    "        #pred = lr.predict(check_feat)\n",
    "        pred = gb.predict(check_data)\n",
    "        score.append(roc_auc_score(check_labels, pred))\n",
    "        \n",
    "        n += 1\n",
    "    print(i, np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in range(1,10,1):\n",
    "#    gb = GradientBoostingClassifier(n_estimators=10, max_depth=i, verbose=1)\n",
    "#    score = cross_val_score(gb, features, labels, cv=3, scoring='roc_auc').mean()\n",
    "#    print(i, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2696            2.09m\n",
      "         2           1.1843            2.10m\n",
      "         3           1.1133            2.07m\n",
      "         4           1.0537            2.04m\n",
      "         5           1.0031            2.00m\n",
      "         6           0.9601            1.98m\n",
      "         7           0.9232            1.95m\n",
      "         8           0.8913            1.92m\n",
      "         9           0.8637            1.89m\n",
      "        10           0.8400            1.86m\n",
      "        20           0.7131            1.58m\n",
      "        30           0.6713            1.31m\n",
      "        40           0.6515            1.05m\n",
      "        50           0.6406           46.71s\n",
      "        60           0.6358           30.34s\n",
      "        70           0.6303           14.34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=4, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=79,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gb = GradientBoostingClassifier(n_estimators=200, max_depth=9, verbose=1)\n",
    "gb = GradientBoostingClassifier(n_estimators=79, max_depth=4, verbose=1)\n",
    "gb.fit(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = pd.DataFrame([f.columns,gb.feature_importances_])\n",
    "importances = importances.transpose()\n",
    "columns=['name','importance']\n",
    "importances.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ln_gr_1</td>\n",
       "      <td>0.279625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group_1</td>\n",
       "      <td>0.273074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>char_38</td>\n",
       "      <td>0.189292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ln_38</td>\n",
       "      <td>0.138525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quadr_38</td>\n",
       "      <td>0.119484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name importance\n",
       "4   ln_gr_1   0.279625\n",
       "1   group_1   0.273074\n",
       "0   char_38   0.189292\n",
       "3     ln_38   0.138525\n",
       "2  quadr_38   0.119484"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.sort_values(by=['importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = df_test[['char_38','group_1']].copy()\n",
    "t['quadr_38'] = t['char_38']**2\n",
    "#f['quadr_gr_1'] = f['group_1']**2\n",
    "t['ln_38'] = t['char_38'].apply(lambda x: np.log(x+0.01))\n",
    "t['ln_gr_1'] = t['group_1'].apply(lambda x: np.log(x+0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#t[t['ln_38']==-np.inf] = -100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test Set Predictions\n",
    "#test_proba = gb.predict_proba(df_test[['char_38','group_1']])\n",
    "test_proba = gb.predict_proba(t)\n",
    "test_preds = test_proba[:,1]\n",
    "\n",
    "# Format for submission\n",
    "output = pd.DataFrame({ 'activity_id' : test_ids, 'outcome': test_preds })\n",
    "output.head()\n",
    "output.to_csv('redhat.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
